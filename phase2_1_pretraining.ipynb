{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fDuynr4oW_Q8"
      },
      "source": [
        "# Phase 2.1: Base Pre-Training for Mathematical Reasoning\n",
        "\n",
        "This notebook demonstrates the complete pre-training infrastructure for training a decoder-only transformer on mixed mathematical and general text corpora.\n",
        "\n",
        "## üöÄ Quick Start\n",
        "\n",
        "**For GPU Training (Recommended):**\n",
        "1. Open this notebook in [Google Colab](https://colab.research.google.com)\n",
        "2. Go to Runtime ‚Üí Change runtime type ‚Üí Select GPU (T4 or better)\n",
        "3. Run all cells\n",
        "\n",
        "**For CPU Testing (Local):**\n",
        "- Just run all cells (will use smaller model and fewer steps)\n",
        "\n",
        "## üì¶ What's Included\n",
        "\n",
        "- Streaming dataset for large-scale corpora\n",
        "- Mixed-domain sampling (ArXiv + General text)\n",
        "- Distributed training support (DDP)\n",
        "- Mixed precision (fp16/bf16)\n",
        "- Gradient accumulation\n",
        "- Learning rate scheduling\n",
        "- Automatic checkpointing\n",
        "- TensorBoard logging"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IV4q0HLlW_Q_"
      },
      "source": [
        "## 1. Setup and Installation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6BFRvs4qW_Q_",
        "outputId": "bfcfb685-09d6-49d1-95ea-807868486630"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úì Running on Google Colab\n",
            "\n",
            "Cloning repository...\n",
            "Cloning into 'AI-Mathematical-Olympiad'...\n",
            "remote: Enumerating objects: 155, done.\u001b[K\n",
            "remote: Counting objects: 100% (155/155), done.\u001b[K\n",
            "remote: Compressing objects: 100% (124/124), done.\u001b[K\n",
            "remote: Total 155 (delta 43), reused 140 (delta 29), pack-reused 0 (from 0)\u001b[K\n",
            "Receiving objects: 100% (155/155), 11.19 MiB | 17.43 MiB/s, done.\n",
            "Resolving deltas: 100% (43/43), done.\n",
            "/content/AI-Mathematical-Olympiad\n",
            "‚úì Repository cloned\n"
          ]
        }
      ],
      "source": [
        "# Check if running on Colab\n",
        "try:\n",
        "    import google.colab\n",
        "    IN_COLAB = True\n",
        "    print(\"‚úì Running on Google Colab\")\n",
        "except ImportError:\n",
        "    IN_COLAB = False\n",
        "    print(\"‚úì Running locally\")\n",
        "\n",
        "# Clone repository if on Colab\n",
        "if IN_COLAB:\n",
        "    print(\"\\nCloning repository...\")\n",
        "    !git clone https://github.com/Alpyaman/AI-Mathematical-Olympiad.git\n",
        "    %cd AI-Mathematical-Olympiad\n",
        "    print(\"‚úì Repository cloned\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rsr0TPe8W_RB",
        "outputId": "a70b7211-c1e9-4ccf-d6c3-40675b4413d3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Installing dependencies...\n",
            "‚úì Dependencies installed\n"
          ]
        }
      ],
      "source": [
        "# Install dependencies\n",
        "print(\"Installing dependencies...\")\n",
        "!pip install -q torch numpy tqdm\n",
        "\n",
        "# Optional: Install TensorBoard for logging\n",
        "!pip install -q tensorboard\n",
        "\n",
        "print(\"‚úì Dependencies installed\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_kpfwzWwW_RB",
        "outputId": "2e20d0ed-5858-4c93-c41f-0e063b7c87eb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PyTorch version: 2.9.0+cu126\n",
            "CUDA available: True\n",
            "CUDA device: NVIDIA L4\n",
            "CUDA memory: 23.80 GB\n"
          ]
        }
      ],
      "source": [
        "# Import required libraries\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import DataLoader\n",
        "import os\n",
        "import json\n",
        "from pathlib import Path\n",
        "\n",
        "print(f\"PyTorch version: {torch.__version__}\")\n",
        "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
        "if torch.cuda.is_available():\n",
        "    print(f\"CUDA device: {torch.cuda.get_device_name(0)}\")\n",
        "    print(f\"CUDA memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.2f} GB\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EC0eWH6gW_RB"
      },
      "source": [
        "## 2. Import Phase 2.1 Components"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uegHbUmCW_RC",
        "outputId": "16df659c-f9c5-4757-92b6-fdd8fdbb1017"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úì All Phase 2.1 components imported successfully\n"
          ]
        }
      ],
      "source": [
        "# Import model and tokenizer\n",
        "from src import (\n",
        "    get_small_config,\n",
        "    get_base_config,\n",
        "    MathTransformerDecoder,\n",
        "    MathTokenizer,\n",
        ")\n",
        "\n",
        "# Import training infrastructure\n",
        "from src.training.pretrainer import PreTrainer, PreTrainingConfig\n",
        "\n",
        "# Import data utilities\n",
        "from src.data.pretraining_dataset import (\n",
        "    create_sample_pretraining_data,\n",
        "    prepare_pretraining_data,\n",
        "    PreTrainingDataCollator,\n",
        ")\n",
        "\n",
        "print(\"‚úì All Phase 2.1 components imported successfully\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ldx8yW0fW_RC"
      },
      "source": [
        "## 3. Configure Training\n",
        "\n",
        "We'll automatically adjust based on available hardware."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SkkWHU_pW_RC",
        "outputId": "9625a06b-af25-4ca4-a1d5-00791750ce75"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üöÄ GPU Training Configuration\n",
            "\n",
            "Training Configuration:\n",
            "  Device: cuda\n",
            "  Model size: small\n",
            "  Batch size: 4\n",
            "  Gradient accumulation: 8\n",
            "  Effective batch size: 32\n",
            "  Max steps: 500\n",
            "  Mixed precision: bf16\n"
          ]
        }
      ],
      "source": [
        "# Detect hardware and configure accordingly\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "USE_GPU = device == \"cuda\"\n",
        "\n",
        "if USE_GPU:\n",
        "    # GPU Configuration - Faster training\n",
        "    print(\"üöÄ GPU Training Configuration\")\n",
        "    MODEL_SIZE = \"small\"  # Can use \"base\" for larger GPUs\n",
        "    BATCH_SIZE = 4\n",
        "    GRAD_ACCUM_STEPS = 8\n",
        "    MAX_STEPS = 500  # Increase to 10000+ for real training\n",
        "    MIXED_PRECISION = \"bf16\" if torch.cuda.is_bf16_supported() else \"fp16\"\n",
        "    NUM_WORKERS = 2\n",
        "else:\n",
        "    # CPU Configuration - Slower but still works\n",
        "    print(\"üíª CPU Training Configuration (Demo Mode)\")\n",
        "    MODEL_SIZE = \"small\"\n",
        "    BATCH_SIZE = 1\n",
        "    GRAD_ACCUM_STEPS = 2\n",
        "    MAX_STEPS = 20  # Very short for CPU demo\n",
        "    MIXED_PRECISION = \"fp32\"\n",
        "    NUM_WORKERS = 0\n",
        "\n",
        "print(f\"\\nTraining Configuration:\")\n",
        "print(f\"  Device: {device}\")\n",
        "print(f\"  Model size: {MODEL_SIZE}\")\n",
        "print(f\"  Batch size: {BATCH_SIZE}\")\n",
        "print(f\"  Gradient accumulation: {GRAD_ACCUM_STEPS}\")\n",
        "print(f\"  Effective batch size: {BATCH_SIZE * GRAD_ACCUM_STEPS}\")\n",
        "print(f\"  Max steps: {MAX_STEPS}\")\n",
        "print(f\"  Mixed precision: {MIXED_PRECISION}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "azCeuIOcW_RD"
      },
      "source": [
        "## 4. Prepare Pre-Training Data\n",
        "\n",
        "We'll create sample mathematical and general text data for demonstration."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 333,
          "referenced_widgets": [
            "76b90960778e468dbbd80d4fd9ab81bd",
            "dd0dafc7d4454c8098c150ad8872c38b",
            "8c685bddc56a4196aa7217ab30a801ca",
            "e99459de05744c3ebdef58422447678f",
            "1b1e5003790a4460b0f12d01c5cc16e4",
            "fd052d145e184ced9308b603eccfd7c2",
            "2771f703545f4055adcff9943f31a18e",
            "f74c7fd7aa594c94a46383fd01eeb97a",
            "97b764d25b9849b9902ea29b729485ca",
            "8c7d3ae3edc34d8ca9dc0421011c11ef",
            "b627ba95bc794891be44803240c5885a",
            "8ceb2e81b74949f9ad499779ae01a77e",
            "29caf808978f45d0a1ebae7da32601e5",
            "1ec9ff7c63a549f1b4cc5846a73da744",
            "9ea27b1fe08a4f7680df3f4d92c4ba7a",
            "cd8fb765699141e3ad8559329d9c22d6",
            "92dcb45df2cc4d3aa042a667312b7645",
            "a54fb5cbf2a54727b46cff028389046a",
            "474e92dc97c34c3aa64a3152e390aa41",
            "20a955dd76cb4e8d9c67c9d0bdc2a56e",
            "b6d144ff9cb048a1948a40b7eb4b6d08",
            "c93debb0a27a4f46b61b5df0de4403fa",
            "fe34392937574f64aae5724614f6850b",
            "10045d16e42540b4970a5a3e56e8dfe5",
            "35e2b1dacda344aba7ec812419bfc614",
            "c29ea4346fdd441fb59cc1e726defac8",
            "b674e92d7bd146b4a61db42c43b37922",
            "ee74f603c41549769d41f751dacba7a3",
            "cfea7e0472d24d78b09d6f47d8a7081c",
            "de82d0042d124e86be5665d1a54ccc4e",
            "95be63a5f87344be8703b6228c01defe",
            "eaa5277d99844e698668316231c5af25",
            "3087d0629b5f4db9b7ff1a699a251ca5",
            "836c3b87f39f4f42a62267aece5cbf67",
            "6435afb639d04839bce01c973994f255",
            "9548fcef781c48e2af2a44d14946cd52",
            "3a3fbe8ed91549b69caa0df281306176",
            "a81e649fce4c4176b95547483109b846",
            "feae3169f177470097f47b64a40d15f4",
            "e1bbb861aea145b3ae46fcea88cfe456",
            "49a6d9455d6c4357a50d3a29c9f40e12",
            "ec927bf70a6e422eb7793cc6404cbfe3",
            "1726b1480fd14e35909b7ae8e07c5dd0",
            "45101758dd514dab81e79084485f64ee",
            "c7c273075c8142b7bbc7c5a9a9f73afc",
            "c0f90fae6a9e4d8fac55551c9f57db5c",
            "2d27d8e95a8042378c6240ee29cf1d5e",
            "950fbde82bc646239909ddfdc9936f6e",
            "cbbe31c9b2c246b2996e56ec3dc40c72",
            "e811602878ad4068b5893a0837d21126",
            "c5adbb8919be45808142509f325ca924",
            "88ab0ea3a2094985b8cb286173506d2b",
            "286baba9d5914de89e2139a55d9bc047",
            "ec6fd79933c34578ae9d70a62ff01764",
            "8d776a0dbe6c451ea0a611a18e526715"
          ]
        },
        "id": "pFqJe6UsW_RD",
        "outputId": "743617ab-1e46-4c07-bdf6-201b82f30175"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üöÄ Preparing REAL data in: ./data/pretraining\n",
            "üìö Downloading Math data (OpenWebMath)...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "README.md: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "76b90960778e468dbbd80d4fd9ab81bd"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Resolving data files:   0%|          | 0/114 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "8ceb2e81b74949f9ad499779ae01a77e"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Saving Math: 10807it [00:07, 1460.28it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   ‚úÖ Math data downloaded successfully.\n",
            "üåç Downloading General (C4) data...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "README.md: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "fe34392937574f64aae5724614f6850b"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Resolving data files:   0%|          | 0/1024 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "836c3b87f39f4f42a62267aece5cbf67"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Resolving data files:   0%|          | 0/1024 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c7c273075c8142b7bbc7c5a9a9f73afc"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Saving General: 12975it [00:07, 1632.44it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   ‚úÖ General data downloaded successfully.\n",
            "\n",
            "‚úÖ Data setup complete. Path: ./data/pretraining\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "# [REPLACEMENT FOR STEP 4]\n",
        "import os\n",
        "import json\n",
        "from datasets import load_dataset\n",
        "from tqdm import tqdm\n",
        "from pathlib import Path\n",
        "\n",
        "# 1. Define the correct path\n",
        "data_dir = \"./data/pretraining\"\n",
        "print(f\"üöÄ Preparing REAL data in: {data_dir}\")\n",
        "\n",
        "# 2. Setup Directories\n",
        "math_dir = Path(data_dir) / \"arxiv\" # Keep folder name 'arxiv' for compatibility\n",
        "general_dir = Path(data_dir) / \"general\"\n",
        "os.makedirs(math_dir, exist_ok=True)\n",
        "os.makedirs(general_dir, exist_ok=True)\n",
        "\n",
        "# 3. Download MATH Data (Source: OpenWebMath)\n",
        "# This is a high-quality dataset of math webpages\n",
        "print(\"üìö Downloading Math data (OpenWebMath)...\")\n",
        "try:\n",
        "    ds_math = load_dataset(\"open-web-math/open-web-math\", split=\"train\", streaming=True)\n",
        "\n",
        "    with open(math_dir / \"math_subset.jsonl\", \"w\", encoding=\"utf-8\") as f:\n",
        "        count = 0\n",
        "        for row in tqdm(ds_math, desc=\"Saving Math\", total=10000):\n",
        "            text = row.get('text', '')\n",
        "            if len(text) > 500:\n",
        "                json.dump({\"text\": text}, f)\n",
        "                f.write(\"\\n\")\n",
        "                count += 1\n",
        "            if count >= 10000:\n",
        "                break\n",
        "    print(\"   ‚úÖ Math data downloaded successfully.\")\n",
        "except Exception as e:\n",
        "    print(f\"   ‚ö†Ô∏è Math download failed: {e}\")\n",
        "\n",
        "# 4. Download General Data (C4)\n",
        "print(\"üåç Downloading General (C4) data...\")\n",
        "try:\n",
        "    ds_general = load_dataset(\"allenai/c4\", \"en\", split=\"train\", streaming=True)\n",
        "\n",
        "    with open(general_dir / \"c4_subset.jsonl\", \"w\", encoding=\"utf-8\") as f:\n",
        "        count = 0\n",
        "        for row in tqdm(ds_general, desc=\"Saving General\", total=10000):\n",
        "            if len(row['text']) > 500:\n",
        "                json.dump({\"text\": row['text']}, f)\n",
        "                f.write(\"\\n\")\n",
        "                count += 1\n",
        "            if count >= 10000:\n",
        "                break\n",
        "    print(\"   ‚úÖ General data downloaded successfully.\")\n",
        "except Exception as e:\n",
        "    print(f\"   ‚ö†Ô∏è General failed: {e}\")\n",
        "\n",
        "print(f\"\\n‚úÖ Data setup complete. Path: {data_dir}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oMPlGoxtW_RD",
        "outputId": "540c63f2-473f-43ac-9ea8-0cc877c67e05"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample ArXiv text:\n",
            "======================================================================\n",
            "Bayes and his¬†Theorem\n",
            "\n",
            "My earlier post on Bayesian probability seems to have generated quite a lot of readers, so this lunchtime I thought I‚Äôd add a little bit of background. The previous discussion started from the result\n",
            "\n",
            "$P(B|AC) = K^{-1}P(B|C)P(A|BC) = K^{-1} P(AB|C)$\n",
            "\n",
            "where\n",
            "\n",
            "$K=P(A|C).$\n",
            "\n",
            "Although this is called Bayes‚Äô theorem, the general form of it as stated here was actually first written down, not by Bayes but by Laplace. What Bayes‚Äô did was derive the special case of this formula for ‚Äúinverting‚Äù the binomial distribution. This distribution gives the probability of x successes in n independent ‚Äútrials‚Äù each having the same probability of success, p; each ‚Äútrial‚Äù has only two possible outcomes (‚Äúsuccess‚Äù or ‚Äúfailure‚Äù). Trials like this are usually called Bernoulli trials, after Daniel Bernoulli. If we ask the question ‚Äúwhat is the probability of exactly x successes from the possible n?‚Äù, the answer is given by the binomial distribution:\n",
            "\n",
            "$P_n(x|n,p)= C(n,x) p^x (1-p)^{n-x}$\n",
            "\n",
            "where\n",
            "\n",
            "$C(n,x)= n!/x!(n-x)!$\n",
            "\n",
            "is the number of distinct combinations of x objects that can be drawn from a pool of n.\n",
            "\n",
            "You can probably see immediately how this arises. The probability of x consecutive successes is p multiplied by itself x times, or px. The probability of (n-x) successive failures is similarly (1-p)n-x. The last two terms basically therefore tell us the probability that we have exactly x successes (since there must be n-x failures). The combinatorial factor in front takes account of the fact that the ordering of successes and failures doesn‚Äôt matter.\n",
            "\n",
            "The binomial distribution applies, for example, to repeated tosses of a coin, in which case p is taken to be 0.5 for a fair coin. A biased coin might have a different value of p, but as long as the tosses are independent the formula still applies. The binomial distribution also applies to problems involving drawing balls from urns: it works exactly if the balls are replaced in the urn after each draw, but it also applies approximately without replacement, as long as the number of draws is much smaller than the number of balls in the urn. I leave it as an exercise to calculate the expectation value of the binomial distribution, but the result is not surprising: E(X)=np. If you toss a fair coin ten times the expectation value for the number of heads is 10 times 0.5, which is five. No surprise there. After another bit of maths, the variance of the distribution can also be found. It is np(1-p).\n",
            "\n",
            "So this gives us the probability of x given a fixed value of p. Bayes was interested in the inverse of this result, the probability of p given x. In other words, Bayes was interested in the answer to the question ‚ÄúIf I perform n independent trials and get x successes, what is the probability distribution of p?‚Äù. This is a classic example of inverse reasoning. He got the correct answer, eventually, but by very convoluted reasoning. In my opinion it is quite difficult to justify the name Bayes‚Äô theorem based on what he actually did, although Laplace did specifically acknowledge this contribution when he derived the general result later, which is no doubt why the theorem is always named in Bayes‚Äô honour.\n",
            "\n",
            "This is not the only example in science where the wrong person‚Äôs name is attached to a result or discovery. In fact, it is almost a law of Nature that any theorem that has a name has the wrong name. I propose that this observation should henceforth be known as Coles‚Äô Law.\n",
            "\n",
            "So who was the mysterious mathematician behind this result? Thomas Bayes was born in 1702, son of Joshua Bayes, who was a Fellow of the Royal Society (FRS) and one of the very first nonconformist ministers to be ordained in England. Thomas was himself ordained and for a while worked with his father in the Presbyterian Meeting House in Leather Lane, near Holborn in London. In 1720 he was a minister in Tunbridge Wells, in Kent. He retired from the church in 1752 and died in 1761. Thomas Bayes didn‚Äôt publish a single paper on mathematics in his own name during his lifetime but despite this was elected a Fellow of the Royal Society (FRS) in 1742. Presumably he had Friends of the Right Sort. He did however write a paper on fluxions in 1736, which was published anonymously. This was probably the grounds on which he was elected an FRS.\n",
            "\n",
            "The paper containing the theorem that now bears his name was published posthumously in the Philosophical Transactions of the Royal Society of London in 1764.\n",
            "\n",
            "P.S. I understand that the authenticity of the picture is open to question. Whoever it actually is, he looks¬† to me a bit like Laurence Olivier‚Ä¶\n",
            "\n",
            "11 Responses to ‚ÄúBayes and his¬†Theorem‚Äù\n",
            "\n",
            "1. Bryn Jones Says:\n",
            "\n",
            "The Royal Society is providing free access to electronic versions of its journals until the end of this month. Readers of this blog might like to look at Thomas Bayes‚Äôs two posthumous publications in the Philosophical Transactions.\n",
            "\n",
            "The first is a short paper about series. The other is the paper about statistics communicated by Richard Price. (The statistics paper may be accessible on a long-term basis because it is one of the Royal Society‚Äôs Trailblazing papers the society provides access to as part of its 350th anniversary celebrations.)\n",
            "\n",
            "Incidentally, both Thomas Bayes and Richard Price were buried in the Bunhill Fields Cemetery in London and their tombs can be seen there today.\n",
            "\n",
            "2. Steve Warren Says:\n",
            "\n",
            "You may be remembered in history as the discoverer of coleslaw, but you weren‚Äôt the first.\n",
            "\n",
            "‚Ä¢ Anton Garrett Says:\n",
            "\n",
            "For years I thought it was ‚Äúcold slaw‚Äù because it was served cold. A good job I never asked for warm slaw.\n",
            "\n",
            "3. telescoper Says:\n",
            "\n",
            "My surname, in Spanish, means ‚ÄúCabbages‚Äù. So it was probably one of my ancestors who invented the chopped variety.\n",
            "\n",
            "4. Anton Garrett Says:\n",
            "\n",
            "Thomas Bayes is now known to have gone to Edinburgh University, where his name appears in the records. He was barred from English universities because his nonconformist family did not have him baptised in the Church of England. (Charles Darwin‚Äôs nonconformist family covered their bets by having baby Charles baptised in the CoE, although perhaps they believed it didn‚Äôt count as a baptism since Charles had no say in it. Tist is why he was able to go to Christ‚Äôs College, Cambridge.)\n",
            "\n",
            "5. ‚ÄúCole‚Äù is an old English word for cabbage, which survives in ‚Äúcole slaw‚Äù. The German word is ‚ÄúKohl‚Äù. (Somehow, I don‚Äôt see PM or President Cabbage being a realistic possibility. üôÇ )\n",
            "\n",
            "Note that Old King Cole is unrelated (etymologically). Of course, this discussion could cause Peter to post a clip of\n",
            "\n",
            "Nat ‚ÄúKing‚Äù Cole\n",
            "(guess what his real surname is).\n",
            "\n",
            "To remind people to pay attention to spelling when they hear words, we‚Äôll close with the Quote of the Day:\n",
            "\n",
            "It‚Äôs important to pay close attention in school. For years I thought that\n",
            "bears masturbated all winter.\n",
            "\n",
            "‚ÄîDamon R. Milhem\n",
            "\n",
            "6. Of course, this discussion could cause Peter to post a clip of\n",
            "Nat King Cole\n",
            "(giess what his real surname is).\n",
            "\n",
            "7. Of course, this discussion could cause Peter to post a clip of\n",
            "Nat King Cole\n",
            "(giess what his real surname is).\n",
            "\n",
            "The first typo was my fault; the extra linebreaks in the second attempt\n",
            "(tested again here) appear to be a new ‚Äúfeature‚Äù.\n",
            "\n",
            "8. telescoper Says:\n",
            "\n",
            "The noun ‚Äúcole‚Äù can be found in English dictionaries as a generic name for plants of the cabbage family. It is related to the German kohl and scottish kail or kale. These are all derived from the latin word colis (or caulis) meaning a stem, which is also the root of the word cauliflower.\n",
            "\n",
            "The surname ‚ÄúCole‚Äù and the variant ‚ÄúColes‚Äù are fairly common in England and Wales, but are not related to the latin word for cabbage. Both are diminutives of the name ‚ÄúNicholas‚Äù.\n",
            "\n",
            "9. [‚Ä¶] I posted a little piece about Bayesian probability. That one and the others that followed it (here and here) proved to be surprisingly popular so I‚Äôve been planning to add a few more posts [‚Ä¶]\n",
            "\n",
            "10. It already has a popular name: Stigler‚Äôs law of eponymy.\n",
            "\n",
            "======================================================================\n",
            "Sample General text:\n",
            "======================================================================\n",
            "Beginners BBQ Class Taking Place in Missoula!\n",
            "Do you want to get better at making delicious BBQ? You will have the opportunity, put this on your calendar now. Thursday, September 22nd join World Class BBQ Champion, Tony Balay from Lonestar Smoke Rangers. He will be teaching a beginner level class for everyone who wants to get better with their culinary skills.\n",
            "He will teach you everything you need to know to compete in a KCBS BBQ competition, including techniques, recipes, timelines, meat selection and trimming, plus smoker and fire information.\n",
            "The cost to be in the class is $35 per person, and for spectators it is free. Included in the cost will be either a t-shirt or apron and you will be tasting samples of each meat that is prepared.\n"
          ]
        }
      ],
      "source": [
        "# Preview the data\n",
        "print(\"Sample ArXiv text:\")\n",
        "print(\"=\" * 70)\n",
        "with open(f\"{data_dir}/arxiv/math_subset.jsonl\", 'r') as f:\n",
        "    sample = json.loads(f.readline())\n",
        "    print(sample['text'])\n",
        "\n",
        "print(\"\\n\" + \"=\" * 70)\n",
        "print(\"Sample General text:\")\n",
        "print(\"=\" * 70)\n",
        "with open(f\"{data_dir}/general/c4_subset.jsonl\", 'r') as f:\n",
        "    sample = json.loads(f.readline())\n",
        "    print(sample['text'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ugk9flWHW_RE"
      },
      "source": [
        "## 5. Initialize Tokenizer\n",
        "\n",
        "Our enhanced mathematical tokenizer with 200+ symbols."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8KVGvjYnW_RE",
        "outputId": "a81c1c20-19cf-4a72-c94d-603f10864470"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Initializing mathematical tokenizer...\n",
            "‚úì Tokenizer initialized\n",
            "  Vocabulary size: 542\n",
            "  Special tokens: {'pad': '<pad>', 'eos': '<eos>', 'bos': '<bos>', 'unk': '<unk>', 'sep': '<sep>', 'math_start': '<math>', 'math_end': '</math>', 'equation_start': '<eq>', 'equation_end': '</eq>', 'proof_start': '<proof>', 'proof_end': '</proof>', 'solution_start': '<solution>', 'solution_end': '</solution>', 'step': '<step>', 'step_end': '</step>', 'answer_start': '<answer>', 'answer_end': '</answer>'}\n",
            "  Mathematical symbols: 200+\n",
            "\n",
            "Tokenization test:\n",
            "  Original: Let f: ‚Ñù ‚Üí ‚Ñù be continuous. Then ‚à´‚ÇÄ¬π f(x)dx exists.\n",
            "  Decoded:  Let f: ‚Ñù ‚Üí ‚Ñù be continuous. Then ‚à´‚ÇÄ¬π f(x)dx exists.\n",
            "  Tokens: 53\n"
          ]
        }
      ],
      "source": [
        "# Initialize tokenizer\n",
        "print(\"Initializing mathematical tokenizer...\")\n",
        "tokenizer = MathTokenizer()\n",
        "\n",
        "print(f\"‚úì Tokenizer initialized\")\n",
        "print(f\"  Vocabulary size: {len(tokenizer):,}\")\n",
        "print(f\"  Special tokens: {tokenizer.SPECIAL_TOKENS}\")\n",
        "print(f\"  Mathematical symbols: 200+\")\n",
        "\n",
        "# Test tokenization\n",
        "test_text = \"Let f: ‚Ñù ‚Üí ‚Ñù be continuous. Then ‚à´‚ÇÄ¬π f(x)dx exists.\"\n",
        "encoded = tokenizer.encode(test_text)\n",
        "decoded = tokenizer.decode(encoded['input_ids'])\n",
        "\n",
        "print(f\"\\nTokenization test:\")\n",
        "print(f\"  Original: {test_text}\")\n",
        "print(f\"  Decoded:  {decoded}\")\n",
        "print(f\"  Tokens: {len(encoded['input_ids'])}\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- DIAGNOSTIC CELL ---\n",
        "print(\"üîç INSPECTING A BATCH...\")\n",
        "batch = next(iter(train_loader))\n",
        "input_ids = batch['input_ids'][0]\n",
        "labels = batch['labels'][0]\n",
        "\n",
        "print(f\"Batch Shape: {batch['input_ids'].shape}\")\n",
        "print(\"-\" * 50)\n",
        "print(\"First 20 Input Tokens:\", input_ids[:20].tolist())\n",
        "print(\"First 20 Labels:      \", labels[:20].tolist())\n",
        "print(\"-\" * 50)\n",
        "print(\"Last 20 Input Tokens: \", input_ids[-20:].tolist())\n",
        "print(\"Last 20 Labels:       \", labels[-20:].tolist())\n",
        "\n",
        "# Check for the Padding Trap\n",
        "pad_id = tokenizer.pad_token_id\n",
        "pad_count = (input_ids == pad_id).sum().item()\n",
        "print(\"-\" * 50)\n",
        "print(f\"Padding Count: {pad_count} / {len(input_ids)} tokens\")\n",
        "\n",
        "if (labels[-1] != -100) and (input_ids[-1] == pad_id):\n",
        "    print(\"üö® CRITICAL ISSUE: The model is training on PADDING tokens!\")\n",
        "    print(\"   The 'labels' for padding positions should be -100, but they are\", labels[-1].item())\n",
        "else:\n",
        "    print(\"‚úÖ Masking looks correct (Labels are -100 for padding).\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ri4Z6fudmsEd",
        "outputId": "d8dc5c4d-9172-4941-eaa5-49268973f25a"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üîç INSPECTING A BATCH...\n",
            "Batch Shape: torch.Size([4, 512])\n",
            "--------------------------------------------------\n",
            "First 20 Input Tokens: [2, 496, 509, 513, 514, 509, 508, 521, 246, 497, 496, 513, 247, 521, 3, 521, 495, 480, 494, 476]\n",
            "First 20 Labels:       [2, 496, 509, 513, 514, 509, 508, 521, 246, 497, 496, 513, 247, 521, 3, 521, 495, 480, 494, 476]\n",
            "--------------------------------------------------\n",
            "Last 20 Input Tokens:  [488, 486, 473, 469, 488, 521, 477, 488, 523, 521, 469, 482, 472, 521, 488, 483, 521, 469, 482, 1]\n",
            "Last 20 Labels:        [488, 486, 473, 469, 488, 521, 477, 488, 523, 521, 469, 482, 472, 521, 488, 483, 521, 469, 482, 1]\n",
            "--------------------------------------------------\n",
            "Padding Count: 0 / 512 tokens\n",
            "‚úÖ Masking looks correct (Labels are -100 for padding).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fcTeU5BZW_RE"
      },
      "source": [
        "## 6. Prepare Streaming Dataset\n",
        "\n",
        "Create a mixed-domain dataset that samples 30% from ArXiv and 70% from general text."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TMxO55SUW_RE",
        "outputId": "029342ed-2030-4536-831a-9eca7c654134"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Preparing mixed-domain streaming dataset...\n",
            "----------------------------------------------------------------------\n",
            "‚úì Streaming dataset created\n",
            "  Data sources: ArXiv (30%), General (70%)\n",
            "  Streaming mode: Yes (memory efficient)\n",
            "  Max sequence length: 512 tokens\n"
          ]
        }
      ],
      "source": [
        "# Prepare streaming dataset\n",
        "print(\"Preparing mixed-domain streaming dataset...\")\n",
        "print(\"-\" * 70)\n",
        "\n",
        "train_dataset = prepare_pretraining_data(\n",
        "    data_dir=data_dir,\n",
        "    sources=[\"arxiv\", \"general\"],\n",
        "    tokenizer=tokenizer,\n",
        "    max_seq_length=512,  # Shorter for demo\n",
        "    mix_weights=[0.3, 0.7],  # 30% math, 70% general\n",
        ")\n",
        "\n",
        "print(\"‚úì Streaming dataset created\")\n",
        "print(f\"  Data sources: ArXiv (30%), General (70%)\")\n",
        "print(f\"  Streaming mode: Yes (memory efficient)\")\n",
        "print(f\"  Max sequence length: 512 tokens\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fXAZng22W_RF",
        "outputId": "dde51ca3-8839-4d01-c18d-f62add4f097d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úì Data loader created\n",
            "  Batch size: 4\n",
            "  Workers: 0\n",
            "\n",
            "Sample batch:\n",
            "  Input shape: torch.Size([4, 512])\n",
            "  Attention mask shape: torch.Size([4, 512])\n",
            "  Labels shape: torch.Size([4, 512])\n"
          ]
        }
      ],
      "source": [
        "# Create data loader\n",
        "collator = PreTrainingDataCollator(pad_token_id=tokenizer.pad_token_id)\n",
        "train_loader = DataLoader(\n",
        "    train_dataset,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    num_workers=0,\n",
        "    collate_fn=collator,\n",
        ")\n",
        "\n",
        "print(\"‚úì Data loader created\")\n",
        "print(f\"  Batch size: {BATCH_SIZE}\")\n",
        "print(f\"  Workers: {0}\")\n",
        "\n",
        "# Test loading a batch\n",
        "sample_batch = next(iter(train_loader))\n",
        "print(f\"\\nSample batch:\")\n",
        "print(f\"  Input shape: {sample_batch['input_ids'].shape}\")\n",
        "print(f\"  Attention mask shape: {sample_batch['attention_mask'].shape}\")\n",
        "print(f\"  Labels shape: {sample_batch['labels'].shape}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W-qDt8kyW_RF"
      },
      "source": [
        "## 7. Initialize Model\n",
        "\n",
        "Create the decoder-only transformer from Phase 1.1."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TNiI58giW_RF",
        "outputId": "8ffb2ebe-0c3f-4c8f-cc7e-f9d4f47a2fb8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Initializing small model...\n",
            "\n",
            "‚úì Model initialized\n",
            "  Architecture: Decoder-only (Llama-style)\n",
            "  Hidden size: 512\n",
            "  Layers: 8\n",
            "  Attention heads: 8\n",
            "  Parameters: 34,118,144 (34,118,144 trainable)\n",
            "  Positional encoding: RoPE (dynamic scaling)\n",
            "  Activation: SwiGLU\n",
            "  Model size: 130.15 MB\n"
          ]
        }
      ],
      "source": [
        "# Get model configuration\n",
        "if MODEL_SIZE == \"small\":\n",
        "    config = get_small_config()\n",
        "    # Further reduce for demo if on CPU\n",
        "    if not USE_GPU:\n",
        "        config.hidden_size = 256\n",
        "        config.num_hidden_layers = 4\n",
        "        config.num_attention_heads = 4\n",
        "        config.num_key_value_heads = 4\n",
        "        config.intermediate_size = 1024\n",
        "elif MODEL_SIZE == \"base\":\n",
        "    config = get_base_config()\n",
        "\n",
        "# Update vocab size to match tokenizer\n",
        "config.vocab_size = len(tokenizer)\n",
        "config.max_position_embeddings = 512\n",
        "\n",
        "# Initialize model\n",
        "print(f\"Initializing {MODEL_SIZE} model...\")\n",
        "model = MathTransformerDecoder(config)\n",
        "\n",
        "# Count parameters\n",
        "num_params = sum(p.numel() for p in model.parameters())\n",
        "num_trainable = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "\n",
        "print(f\"\\n‚úì Model initialized\")\n",
        "print(f\"  Architecture: Decoder-only (Llama-style)\")\n",
        "print(f\"  Hidden size: {config.hidden_size}\")\n",
        "print(f\"  Layers: {config.num_hidden_layers}\")\n",
        "print(f\"  Attention heads: {config.num_attention_heads}\")\n",
        "print(f\"  Parameters: {num_params:,} ({num_trainable:,} trainable)\")\n",
        "print(f\"  Positional encoding: RoPE (dynamic scaling)\")\n",
        "print(f\"  Activation: SwiGLU\")\n",
        "\n",
        "# Show model size in MB\n",
        "param_size_mb = num_params * 4 / (1024 ** 2)  # 4 bytes per float32 param\n",
        "print(f\"  Model size: {param_size_mb:.2f} MB\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# [REPLACEMENT FOR PRETRAINER CLASS - CORRECTED]\n",
        "from typing import Dict\n",
        "import torch.nn as nn\n",
        "from torch.amp import autocast\n",
        "\n",
        "def fixed_train_step(self, batch: Dict[str, torch.Tensor]) -> float:\n",
        "    \"\"\"\n",
        "    Perform a single training step with CORRECT label shifting and Type handling.\n",
        "    \"\"\"\n",
        "    # Move batch to device\n",
        "    batch = {k: v.to(self.device) for k, v in batch.items()}\n",
        "\n",
        "    # Forward pass with mixed precision\n",
        "    with autocast(\"cuda\", dtype=self.dtype, enabled=self.use_amp):\n",
        "        outputs = self.model(\n",
        "            input_ids=batch[\"input_ids\"],\n",
        "            attention_mask=batch[\"attention_mask\"],\n",
        "        )\n",
        "\n",
        "        # --- FIX 1: Extract Logits correctly ---\n",
        "        if isinstance(outputs, dict):\n",
        "            logits = outputs['logits']\n",
        "        else:\n",
        "            logits = outputs\n",
        "        # ---------------------------------------\n",
        "\n",
        "        # --- FIX 2: Shift logits and labels ---\n",
        "        # We drop the last prediction (nothing to compare to)\n",
        "        # and drop the first label (nothing predicts it)\n",
        "        shift_logits = logits[..., :-1, :].contiguous()\n",
        "        shift_labels = batch[\"labels\"][..., 1:].contiguous()\n",
        "        # ------------------------------------\n",
        "\n",
        "        # Compute loss on shifted tensors\n",
        "        loss = nn.functional.cross_entropy(\n",
        "            shift_logits.reshape(-1, shift_logits.size(-1)),\n",
        "            shift_labels.reshape(-1),\n",
        "            ignore_index=-100,\n",
        "        )\n",
        "\n",
        "        # Scale loss for gradient accumulation\n",
        "        loss = loss / self.config.gradient_accumulation_steps\n",
        "\n",
        "    # Backward pass\n",
        "    if self.scaler is not None:\n",
        "        self.scaler.scale(loss).backward()\n",
        "    else:\n",
        "        loss.backward()\n",
        "\n",
        "    return loss.item() * self.config.gradient_accumulation_steps\n",
        "\n",
        "# Apply the fix to the existing class\n",
        "PreTrainer.train_step = fixed_train_step\n",
        "print(\"‚úÖ Patched PreTrainer with Logit Extraction + Shifting Logic\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P_FbyrsUqLsI",
        "outputId": "6a679a96-0db4-4e75-d2f0-fda0463cd24c"
      },
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Patched PreTrainer with Logit Extraction + Shifting Logic\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TJjfwTvEW_RG"
      },
      "source": [
        "## 8. Configure Pre-Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U2y83s10W_RG",
        "outputId": "1227c0db-3fcb-49bd-cc82-c21aef685c09"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úì Real Training Configuration Applied\n",
            "  Target: 8000 micro-steps\n",
            "  Estimated Duration: ~10-15 minutes\n"
          ]
        }
      ],
      "source": [
        "# [REPLACEMENT FOR STEP 8]\n",
        "training_config = PreTrainingConfig(\n",
        "    model_config_name=MODEL_SIZE,\n",
        "    vocab_size=config.vocab_size,\n",
        "    max_seq_length=512,\n",
        "    data_dir=data_dir,\n",
        "\n",
        "    # --- FIX 1: Increase Steps ---\n",
        "    # We want ~1000 effective updates.\n",
        "    # 1000 updates * 8 accum steps = 8000 micro steps.\n",
        "    max_steps=8000,\n",
        "\n",
        "    micro_batch_size=BATCH_SIZE,\n",
        "    gradient_accumulation_steps=GRAD_ACCUM_STEPS, # 8\n",
        "\n",
        "    warmup_steps=500,\n",
        "    learning_rate=3e-4,\n",
        "\n",
        "    mixed_precision=MIXED_PRECISION,\n",
        "    gradient_checkpointing=USE_GPU,\n",
        "\n",
        "    checkpoint_dir=\"./checkpoints/pretraining_notebook\",\n",
        "    save_interval=2000,\n",
        "\n",
        "    # --- FIX 2: Align Logging ---\n",
        "    # To ensure we see logs, set log_interval relative to accum steps\n",
        "    # But since the internal logic is tricky, we rely on the final result\n",
        "    # or set it to 1 to force it to try often.\n",
        "    log_interval=1,\n",
        "\n",
        "    use_wandb=False,\n",
        "    use_tensorboard=False,\n",
        "    num_workers=0,\n",
        "    seed=42,\n",
        ")\n",
        "\n",
        "print(\"‚úì Real Training Configuration Applied\")\n",
        "print(f\"  Target: {training_config.max_steps} micro-steps\")\n",
        "print(f\"  Estimated Duration: ~10-15 minutes\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# [REPLACEMENT FOR DATA COLLATOR]\n",
        "import torch\n",
        "from torch.nn.utils.rnn import pad_sequence\n",
        "\n",
        "class RobustDataCollator:\n",
        "    \"\"\"\n",
        "    A robust collator that:\n",
        "    1. Pads sequences to the longest length in the batch.\n",
        "    2. Ensures padding is masked in the labels (-100).\n",
        "    \"\"\"\n",
        "    def __init__(self, tokenizer):\n",
        "        self.tokenizer = tokenizer\n",
        "        # Ensure we have a valid pad ID, default to 0 if None\n",
        "        self.pad_id = tokenizer.pad_token_id if tokenizer.pad_token_id is not None else 0\n",
        "\n",
        "    def __call__(self, features):\n",
        "        # 1. Extract inputs (they might vary in length)\n",
        "        input_ids_list = [f['input_ids'] for f in features]\n",
        "        attention_mask_list = [f['attention_mask'] for f in features]\n",
        "\n",
        "        # 2. Dynamically pad the batch (makes them all same length)\n",
        "        # batch_first=True results in (batch_size, seq_len)\n",
        "        input_ids = pad_sequence(input_ids_list, batch_first=True, padding_value=self.pad_id)\n",
        "        attention_mask = pad_sequence(attention_mask_list, batch_first=True, padding_value=0)\n",
        "\n",
        "        # 3. Create labels\n",
        "        labels = input_ids.clone()\n",
        "\n",
        "        # 4. Mask padding tokens so loss is NOT calculated on them\n",
        "        # Set label to -100 wherever the input is a pad token\n",
        "        labels[input_ids == self.pad_id] = -100\n",
        "\n",
        "        return {\n",
        "            \"input_ids\": input_ids,\n",
        "            \"attention_mask\": attention_mask,\n",
        "            \"labels\": labels\n",
        "        }\n",
        "\n",
        "# Re-initialize with the SMART collator\n",
        "print(\"üîÑ Rebuilding Data Loader with Dynamic Padding...\")\n",
        "fix_collator = RobustDataCollator(tokenizer)\n",
        "\n",
        "train_loader = DataLoader(\n",
        "    train_dataset,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    num_workers=0,\n",
        "    collate_fn=fix_collator,\n",
        ")\n",
        "print(\"‚úÖ Loader ready.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jY16gqk5nBY8",
        "outputId": "a0bcdcf8-e594-46c1-f5b3-fb87b499830c"
      },
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üîÑ Rebuilding Data Loader with Dynamic Padding...\n",
            "‚úÖ Loader ready.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RoTECI46W_RG"
      },
      "source": [
        "## 9. Initialize Pre-Trainer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3KYKOHl8W_RH",
        "outputId": "f2054129-d882-40ba-faf8-685d26440f69"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Initializing Pre-Trainer...\n",
            "======================================================================\n",
            "\n",
            "======================================================================\n",
            "PRE-TRAINING CONFIGURATION\n",
            "======================================================================\n",
            "Model: small\n",
            "Max steps: 8,000\n",
            "Batch size: 4 (per device)\n",
            "Gradient accumulation: 8 steps\n",
            "Effective batch size: 32\n",
            "Learning rate: 0.0003\n",
            "Mixed precision: bf16\n",
            "Gradient checkpointing: True\n",
            "World size: 1\n",
            "Device: cuda:0\n",
            "======================================================================\n",
            "\n",
            "\n",
            "‚úì Pre-Trainer ready!\n"
          ]
        }
      ],
      "source": [
        "# Initialize pre-trainer\n",
        "print(\"Initializing Pre-Trainer...\")\n",
        "print(\"=\" * 70)\n",
        "\n",
        "trainer = PreTrainer(\n",
        "    model=model,\n",
        "    config=training_config,\n",
        "    train_dataloader=train_loader,\n",
        "    val_dataloader=None,\n",
        ")\n",
        "\n",
        "print(\"\\n‚úì Pre-Trainer ready!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x0oXJ50HW_RH"
      },
      "source": [
        "## 10. Run Pre-Training\n",
        "\n",
        "This is where the magic happens! üéØ"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FsQXsn3IW_RH",
        "outputId": "502890af-c89e-4454-c612-95eec09a894e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "======================================================================\n",
            "STARTING BASE PRE-TRAINING\n",
            "======================================================================\n",
            "\n",
            "Starting pre-training from step 0...\n",
            "Step 7/8000 | Loss: 17.2963 | LR: 6.00e-07 | Tokens: 2,048 | Time: 1.0s\n",
            "Step 15/8000 | Loss: 17.3815 | LR: 1.20e-06 | Tokens: 4,096 | Time: 1.4s\n",
            "Step 23/8000 | Loss: 17.2314 | LR: 1.80e-06 | Tokens: 6,144 | Time: 1.8s\n",
            "Step 31/8000 | Loss: 17.0230 | LR: 2.40e-06 | Tokens: 8,192 | Time: 2.3s\n",
            "Step 39/8000 | Loss: 17.1445 | LR: 3.00e-06 | Tokens: 10,240 | Time: 2.7s\n",
            "Step 47/8000 | Loss: 17.1857 | LR: 3.60e-06 | Tokens: 12,288 | Time: 3.1s\n",
            "Step 55/8000 | Loss: 16.9725 | LR: 4.20e-06 | Tokens: 14,336 | Time: 3.6s\n",
            "Step 63/8000 | Loss: 16.9856 | LR: 4.80e-06 | Tokens: 16,384 | Time: 4.0s\n",
            "Step 71/8000 | Loss: 16.7718 | LR: 5.40e-06 | Tokens: 18,432 | Time: 4.4s\n",
            "Step 79/8000 | Loss: 16.5245 | LR: 6.00e-06 | Tokens: 20,480 | Time: 4.8s\n",
            "Step 87/8000 | Loss: 16.3853 | LR: 6.60e-06 | Tokens: 22,528 | Time: 5.2s\n",
            "Step 95/8000 | Loss: 15.8645 | LR: 7.20e-06 | Tokens: 24,576 | Time: 5.7s\n",
            "Step 103/8000 | Loss: 15.8225 | LR: 7.80e-06 | Tokens: 26,624 | Time: 6.3s\n",
            "Step 111/8000 | Loss: 15.4389 | LR: 8.40e-06 | Tokens: 28,672 | Time: 6.8s\n",
            "Step 119/8000 | Loss: 15.1517 | LR: 9.00e-06 | Tokens: 30,720 | Time: 7.2s\n",
            "Step 127/8000 | Loss: 14.5337 | LR: 9.60e-06 | Tokens: 32,768 | Time: 7.6s\n",
            "Step 135/8000 | Loss: 14.1417 | LR: 1.02e-05 | Tokens: 34,816 | Time: 8.1s\n",
            "Step 143/8000 | Loss: 13.4922 | LR: 1.08e-05 | Tokens: 36,864 | Time: 8.5s\n",
            "Step 151/8000 | Loss: 12.8251 | LR: 1.14e-05 | Tokens: 38,912 | Time: 8.9s\n",
            "Step 159/8000 | Loss: 12.1612 | LR: 1.20e-05 | Tokens: 40,960 | Time: 9.3s\n",
            "Step 167/8000 | Loss: 11.2762 | LR: 1.26e-05 | Tokens: 43,008 | Time: 9.8s\n",
            "Step 175/8000 | Loss: 10.6457 | LR: 1.32e-05 | Tokens: 45,056 | Time: 10.2s\n",
            "Step 183/8000 | Loss: 9.7924 | LR: 1.38e-05 | Tokens: 47,104 | Time: 10.6s\n",
            "Step 191/8000 | Loss: 9.0004 | LR: 1.44e-05 | Tokens: 49,152 | Time: 11.1s\n",
            "Step 199/8000 | Loss: 8.3697 | LR: 1.50e-05 | Tokens: 51,200 | Time: 11.5s\n",
            "Step 207/8000 | Loss: 7.8680 | LR: 1.56e-05 | Tokens: 53,248 | Time: 11.9s\n",
            "Step 215/8000 | Loss: 7.4144 | LR: 1.62e-05 | Tokens: 55,296 | Time: 12.3s\n",
            "Step 223/8000 | Loss: 6.9865 | LR: 1.68e-05 | Tokens: 57,344 | Time: 12.7s\n",
            "Step 231/8000 | Loss: 6.5173 | LR: 1.74e-05 | Tokens: 59,392 | Time: 13.1s\n",
            "Step 239/8000 | Loss: 6.0827 | LR: 1.80e-05 | Tokens: 61,440 | Time: 13.6s\n",
            "Step 247/8000 | Loss: 5.7402 | LR: 1.86e-05 | Tokens: 63,488 | Time: 14.0s\n",
            "Step 255/8000 | Loss: 5.2802 | LR: 1.92e-05 | Tokens: 65,536 | Time: 14.4s\n",
            "Step 263/8000 | Loss: 4.9178 | LR: 1.98e-05 | Tokens: 67,584 | Time: 14.9s\n",
            "Step 271/8000 | Loss: 4.5741 | LR: 2.04e-05 | Tokens: 69,632 | Time: 15.3s\n",
            "Step 279/8000 | Loss: 4.2300 | LR: 2.10e-05 | Tokens: 71,680 | Time: 15.7s\n",
            "Step 287/8000 | Loss: 4.1342 | LR: 2.16e-05 | Tokens: 73,728 | Time: 16.1s\n",
            "Step 295/8000 | Loss: 3.9094 | LR: 2.22e-05 | Tokens: 75,776 | Time: 16.6s\n",
            "Step 303/8000 | Loss: 3.7633 | LR: 2.28e-05 | Tokens: 77,824 | Time: 17.0s\n",
            "Step 311/8000 | Loss: 3.6340 | LR: 2.34e-05 | Tokens: 79,872 | Time: 17.4s\n",
            "Step 319/8000 | Loss: 3.6165 | LR: 2.40e-05 | Tokens: 81,920 | Time: 17.8s\n",
            "Step 327/8000 | Loss: 3.4502 | LR: 2.46e-05 | Tokens: 83,968 | Time: 18.4s\n",
            "Step 335/8000 | Loss: 3.3703 | LR: 2.52e-05 | Tokens: 86,016 | Time: 18.9s\n",
            "Step 343/8000 | Loss: 3.3509 | LR: 2.58e-05 | Tokens: 88,064 | Time: 19.3s\n",
            "Step 351/8000 | Loss: 3.2902 | LR: 2.64e-05 | Tokens: 90,112 | Time: 19.7s\n",
            "Step 359/8000 | Loss: 3.2773 | LR: 2.70e-05 | Tokens: 92,160 | Time: 20.1s\n",
            "Step 367/8000 | Loss: 3.2734 | LR: 2.76e-05 | Tokens: 94,208 | Time: 20.6s\n",
            "Step 375/8000 | Loss: 3.2739 | LR: 2.82e-05 | Tokens: 96,256 | Time: 21.0s\n",
            "Step 383/8000 | Loss: 3.1242 | LR: 2.88e-05 | Tokens: 98,304 | Time: 21.4s\n",
            "Step 391/8000 | Loss: 3.2037 | LR: 2.94e-05 | Tokens: 100,352 | Time: 21.8s\n",
            "Step 399/8000 | Loss: 3.1346 | LR: 3.00e-05 | Tokens: 102,400 | Time: 22.2s\n",
            "Step 407/8000 | Loss: 3.1405 | LR: 3.06e-05 | Tokens: 104,448 | Time: 22.7s\n",
            "Step 415/8000 | Loss: 3.0715 | LR: 3.12e-05 | Tokens: 106,496 | Time: 23.1s\n",
            "Step 423/8000 | Loss: 3.0792 | LR: 3.18e-05 | Tokens: 108,544 | Time: 23.6s\n",
            "Step 431/8000 | Loss: 3.2191 | LR: 3.24e-05 | Tokens: 110,592 | Time: 24.0s\n",
            "Step 439/8000 | Loss: 2.9825 | LR: 3.30e-05 | Tokens: 112,640 | Time: 24.4s\n",
            "Step 447/8000 | Loss: 3.0452 | LR: 3.36e-05 | Tokens: 114,688 | Time: 24.8s\n",
            "Step 455/8000 | Loss: 2.9930 | LR: 3.42e-05 | Tokens: 116,736 | Time: 25.2s\n",
            "Step 463/8000 | Loss: 2.9969 | LR: 3.48e-05 | Tokens: 118,784 | Time: 25.6s\n",
            "Step 471/8000 | Loss: 2.9310 | LR: 3.54e-05 | Tokens: 120,832 | Time: 26.1s\n",
            "Step 479/8000 | Loss: 3.0010 | LR: 3.60e-05 | Tokens: 122,880 | Time: 26.5s\n",
            "Step 487/8000 | Loss: 2.8787 | LR: 3.66e-05 | Tokens: 124,928 | Time: 26.9s\n",
            "Step 495/8000 | Loss: 2.9065 | LR: 3.72e-05 | Tokens: 126,976 | Time: 27.3s\n",
            "Step 503/8000 | Loss: 2.9923 | LR: 3.78e-05 | Tokens: 129,024 | Time: 27.7s\n",
            "Step 511/8000 | Loss: 2.9473 | LR: 3.84e-05 | Tokens: 131,072 | Time: 28.2s\n",
            "Step 519/8000 | Loss: 2.8845 | LR: 3.90e-05 | Tokens: 133,120 | Time: 28.6s\n",
            "Step 527/8000 | Loss: 2.8735 | LR: 3.96e-05 | Tokens: 135,168 | Time: 29.0s\n",
            "Step 535/8000 | Loss: 2.8581 | LR: 4.02e-05 | Tokens: 137,216 | Time: 29.5s\n",
            "Step 543/8000 | Loss: 2.8594 | LR: 4.08e-05 | Tokens: 139,264 | Time: 29.9s\n",
            "Step 551/8000 | Loss: 2.8401 | LR: 4.14e-05 | Tokens: 141,312 | Time: 30.4s\n",
            "Step 559/8000 | Loss: 2.8450 | LR: 4.20e-05 | Tokens: 143,360 | Time: 30.8s\n",
            "Step 567/8000 | Loss: 2.8795 | LR: 4.26e-05 | Tokens: 145,408 | Time: 31.2s\n",
            "Step 575/8000 | Loss: 2.9882 | LR: 4.32e-05 | Tokens: 147,456 | Time: 31.6s\n",
            "Step 583/8000 | Loss: 2.8031 | LR: 4.38e-05 | Tokens: 149,504 | Time: 32.1s\n",
            "Step 591/8000 | Loss: 2.7765 | LR: 4.44e-05 | Tokens: 151,552 | Time: 32.5s\n",
            "Step 599/8000 | Loss: 2.8103 | LR: 4.50e-05 | Tokens: 153,600 | Time: 33.0s\n",
            "Step 607/8000 | Loss: 2.8399 | LR: 4.56e-05 | Tokens: 155,648 | Time: 33.4s\n",
            "Step 615/8000 | Loss: 2.8011 | LR: 4.62e-05 | Tokens: 157,696 | Time: 33.8s\n",
            "Step 623/8000 | Loss: 2.8436 | LR: 4.68e-05 | Tokens: 159,744 | Time: 34.2s\n",
            "Step 631/8000 | Loss: 2.8437 | LR: 4.74e-05 | Tokens: 161,792 | Time: 34.7s\n",
            "Step 639/8000 | Loss: 2.7507 | LR: 4.80e-05 | Tokens: 163,840 | Time: 35.1s\n",
            "Step 647/8000 | Loss: 2.8312 | LR: 4.86e-05 | Tokens: 165,888 | Time: 35.6s\n",
            "Step 655/8000 | Loss: 2.7746 | LR: 4.92e-05 | Tokens: 167,936 | Time: 36.0s\n",
            "Step 663/8000 | Loss: 2.8320 | LR: 4.98e-05 | Tokens: 169,984 | Time: 36.4s\n",
            "Step 671/8000 | Loss: 2.7679 | LR: 5.04e-05 | Tokens: 172,032 | Time: 36.9s\n",
            "Step 679/8000 | Loss: 2.7718 | LR: 5.10e-05 | Tokens: 174,080 | Time: 37.3s\n",
            "Step 687/8000 | Loss: 2.8357 | LR: 5.16e-05 | Tokens: 176,128 | Time: 37.7s\n",
            "Step 695/8000 | Loss: 2.7526 | LR: 5.22e-05 | Tokens: 178,176 | Time: 38.1s\n",
            "Step 703/8000 | Loss: 2.7981 | LR: 5.28e-05 | Tokens: 180,224 | Time: 38.5s\n",
            "Step 711/8000 | Loss: 2.7144 | LR: 5.34e-05 | Tokens: 182,272 | Time: 39.0s\n",
            "Step 719/8000 | Loss: 2.8384 | LR: 5.40e-05 | Tokens: 184,320 | Time: 39.4s\n",
            "Step 727/8000 | Loss: 2.7615 | LR: 5.46e-05 | Tokens: 186,368 | Time: 39.8s\n",
            "Step 735/8000 | Loss: 2.7623 | LR: 5.52e-05 | Tokens: 188,416 | Time: 40.2s\n",
            "Step 743/8000 | Loss: 2.7069 | LR: 5.58e-05 | Tokens: 190,464 | Time: 40.6s\n",
            "Step 751/8000 | Loss: 2.6925 | LR: 5.64e-05 | Tokens: 192,512 | Time: 41.0s\n",
            "Step 759/8000 | Loss: 2.8411 | LR: 5.70e-05 | Tokens: 194,560 | Time: 41.4s\n",
            "Step 767/8000 | Loss: 2.7417 | LR: 5.76e-05 | Tokens: 196,608 | Time: 41.9s\n",
            "Step 775/8000 | Loss: 2.7271 | LR: 5.82e-05 | Tokens: 198,656 | Time: 42.3s\n",
            "Step 783/8000 | Loss: 2.7175 | LR: 5.88e-05 | Tokens: 200,704 | Time: 42.8s\n",
            "Step 791/8000 | Loss: 2.7277 | LR: 5.94e-05 | Tokens: 202,752 | Time: 43.2s\n",
            "Step 799/8000 | Loss: 2.7473 | LR: 6.00e-05 | Tokens: 204,800 | Time: 43.6s\n",
            "Step 807/8000 | Loss: 2.7910 | LR: 6.06e-05 | Tokens: 206,848 | Time: 44.1s\n",
            "Step 815/8000 | Loss: 2.7309 | LR: 6.12e-05 | Tokens: 208,896 | Time: 44.5s\n",
            "Step 823/8000 | Loss: 2.6963 | LR: 6.18e-05 | Tokens: 210,944 | Time: 44.9s\n",
            "Step 831/8000 | Loss: 2.7403 | LR: 6.24e-05 | Tokens: 212,992 | Time: 45.4s\n",
            "Step 839/8000 | Loss: 2.7577 | LR: 6.30e-05 | Tokens: 215,040 | Time: 45.8s\n",
            "Step 847/8000 | Loss: 2.7093 | LR: 6.36e-05 | Tokens: 217,088 | Time: 46.2s\n",
            "Step 855/8000 | Loss: 2.6887 | LR: 6.42e-05 | Tokens: 219,136 | Time: 46.6s\n",
            "Step 863/8000 | Loss: 2.6960 | LR: 6.48e-05 | Tokens: 221,184 | Time: 47.1s\n",
            "Step 871/8000 | Loss: 2.7507 | LR: 6.54e-05 | Tokens: 223,232 | Time: 47.5s\n",
            "Step 879/8000 | Loss: 2.7045 | LR: 6.60e-05 | Tokens: 225,280 | Time: 48.0s\n",
            "Step 887/8000 | Loss: 2.7637 | LR: 6.66e-05 | Tokens: 227,328 | Time: 48.6s\n",
            "Step 895/8000 | Loss: 2.6964 | LR: 6.72e-05 | Tokens: 229,376 | Time: 49.0s\n",
            "Step 903/8000 | Loss: 2.6427 | LR: 6.78e-05 | Tokens: 231,424 | Time: 49.4s\n",
            "Step 911/8000 | Loss: 2.7418 | LR: 6.84e-05 | Tokens: 233,472 | Time: 49.8s\n",
            "Step 919/8000 | Loss: 2.6851 | LR: 6.90e-05 | Tokens: 235,520 | Time: 50.2s\n",
            "Step 927/8000 | Loss: 2.6448 | LR: 6.96e-05 | Tokens: 237,568 | Time: 50.6s\n",
            "Step 935/8000 | Loss: 2.6581 | LR: 7.02e-05 | Tokens: 239,616 | Time: 51.0s\n",
            "Step 943/8000 | Loss: 2.6905 | LR: 7.08e-05 | Tokens: 241,664 | Time: 51.5s\n",
            "Step 951/8000 | Loss: 2.6352 | LR: 7.14e-05 | Tokens: 243,712 | Time: 51.9s\n",
            "Step 959/8000 | Loss: 2.7087 | LR: 7.20e-05 | Tokens: 245,760 | Time: 52.4s\n",
            "Step 967/8000 | Loss: 2.6645 | LR: 7.26e-05 | Tokens: 247,808 | Time: 52.9s\n",
            "Step 975/8000 | Loss: 2.5910 | LR: 7.32e-05 | Tokens: 249,856 | Time: 53.3s\n",
            "Step 983/8000 | Loss: 2.6350 | LR: 7.38e-05 | Tokens: 251,904 | Time: 53.7s\n",
            "Step 991/8000 | Loss: 2.6819 | LR: 7.44e-05 | Tokens: 253,952 | Time: 54.2s\n",
            "Step 999/8000 | Loss: 2.6503 | LR: 7.50e-05 | Tokens: 256,000 | Time: 54.6s\n",
            "Step 1007/8000 | Loss: 2.7106 | LR: 7.56e-05 | Tokens: 258,048 | Time: 55.1s\n",
            "Step 1015/8000 | Loss: 2.6834 | LR: 7.62e-05 | Tokens: 260,096 | Time: 55.5s\n",
            "Step 1023/8000 | Loss: 2.6539 | LR: 7.68e-05 | Tokens: 262,144 | Time: 56.0s\n",
            "Step 1031/8000 | Loss: 2.6513 | LR: 7.74e-05 | Tokens: 264,192 | Time: 56.4s\n",
            "Step 1039/8000 | Loss: 2.6619 | LR: 7.80e-05 | Tokens: 266,240 | Time: 56.8s\n",
            "Step 1047/8000 | Loss: 2.6343 | LR: 7.86e-05 | Tokens: 268,288 | Time: 57.2s\n",
            "Step 1055/8000 | Loss: 2.6507 | LR: 7.92e-05 | Tokens: 270,336 | Time: 57.7s\n",
            "Step 1063/8000 | Loss: 2.7000 | LR: 7.98e-05 | Tokens: 272,384 | Time: 58.1s\n",
            "Step 1071/8000 | Loss: 2.6187 | LR: 8.04e-05 | Tokens: 274,432 | Time: 58.5s\n",
            "Step 1079/8000 | Loss: 2.6201 | LR: 8.10e-05 | Tokens: 276,480 | Time: 58.9s\n",
            "Step 1087/8000 | Loss: 2.5701 | LR: 8.16e-05 | Tokens: 278,528 | Time: 59.3s\n",
            "Step 1095/8000 | Loss: 2.6321 | LR: 8.22e-05 | Tokens: 280,576 | Time: 59.8s\n",
            "Step 1103/8000 | Loss: 2.5968 | LR: 8.28e-05 | Tokens: 282,624 | Time: 60.2s\n",
            "Step 1111/8000 | Loss: 2.6546 | LR: 8.34e-05 | Tokens: 284,672 | Time: 60.6s\n",
            "Step 1119/8000 | Loss: 2.5993 | LR: 8.40e-05 | Tokens: 286,720 | Time: 61.0s\n",
            "Step 1127/8000 | Loss: 2.5940 | LR: 8.46e-05 | Tokens: 288,768 | Time: 61.5s\n",
            "Step 1135/8000 | Loss: 2.6160 | LR: 8.52e-05 | Tokens: 290,816 | Time: 61.9s\n",
            "Step 1143/8000 | Loss: 2.5624 | LR: 8.58e-05 | Tokens: 292,864 | Time: 62.4s\n",
            "Step 1151/8000 | Loss: 2.6491 | LR: 8.64e-05 | Tokens: 294,912 | Time: 62.9s\n",
            "Step 1159/8000 | Loss: 2.5483 | LR: 8.70e-05 | Tokens: 296,960 | Time: 63.3s\n",
            "Step 1167/8000 | Loss: 2.5767 | LR: 8.76e-05 | Tokens: 299,008 | Time: 63.7s\n",
            "Step 1175/8000 | Loss: 2.5738 | LR: 8.82e-05 | Tokens: 301,056 | Time: 64.2s\n",
            "Step 1183/8000 | Loss: 2.5635 | LR: 8.88e-05 | Tokens: 303,104 | Time: 64.6s\n",
            "Step 1191/8000 | Loss: 2.5237 | LR: 8.94e-05 | Tokens: 305,152 | Time: 65.0s\n",
            "Step 1199/8000 | Loss: 2.5642 | LR: 9.00e-05 | Tokens: 307,200 | Time: 65.4s\n",
            "Step 1207/8000 | Loss: 2.5618 | LR: 9.06e-05 | Tokens: 309,248 | Time: 65.8s\n",
            "Step 1215/8000 | Loss: 2.4985 | LR: 9.12e-05 | Tokens: 311,296 | Time: 66.2s\n",
            "Step 1223/8000 | Loss: 2.4871 | LR: 9.18e-05 | Tokens: 313,344 | Time: 66.6s\n",
            "Step 1231/8000 | Loss: 2.5839 | LR: 9.24e-05 | Tokens: 315,392 | Time: 67.1s\n",
            "Step 1239/8000 | Loss: 2.4975 | LR: 9.30e-05 | Tokens: 317,440 | Time: 67.5s\n",
            "Step 1247/8000 | Loss: 2.5215 | LR: 9.36e-05 | Tokens: 319,488 | Time: 67.9s\n",
            "Step 1255/8000 | Loss: 2.5638 | LR: 9.42e-05 | Tokens: 321,536 | Time: 68.3s\n",
            "Step 1263/8000 | Loss: 2.5199 | LR: 9.48e-05 | Tokens: 323,584 | Time: 68.8s\n",
            "Step 1271/8000 | Loss: 2.6115 | LR: 9.54e-05 | Tokens: 325,632 | Time: 69.2s\n",
            "Step 1279/8000 | Loss: 2.5360 | LR: 9.60e-05 | Tokens: 327,680 | Time: 69.7s\n",
            "Step 1287/8000 | Loss: 2.5163 | LR: 9.66e-05 | Tokens: 329,728 | Time: 70.1s\n",
            "Step 1295/8000 | Loss: 2.4699 | LR: 9.72e-05 | Tokens: 331,776 | Time: 70.5s\n",
            "Step 1303/8000 | Loss: 2.5244 | LR: 9.78e-05 | Tokens: 333,824 | Time: 71.0s\n",
            "Step 1311/8000 | Loss: 2.4609 | LR: 9.84e-05 | Tokens: 335,872 | Time: 71.4s\n",
            "Step 1319/8000 | Loss: 2.5205 | LR: 9.90e-05 | Tokens: 337,920 | Time: 71.8s\n",
            "Step 1327/8000 | Loss: 2.4670 | LR: 9.96e-05 | Tokens: 339,968 | Time: 72.3s\n",
            "Step 1335/8000 | Loss: 2.5494 | LR: 1.00e-04 | Tokens: 342,016 | Time: 72.7s\n",
            "Step 1343/8000 | Loss: 2.5860 | LR: 1.01e-04 | Tokens: 344,064 | Time: 73.1s\n",
            "Step 1351/8000 | Loss: 2.5651 | LR: 1.01e-04 | Tokens: 346,112 | Time: 73.5s\n",
            "Step 1359/8000 | Loss: 2.4403 | LR: 1.02e-04 | Tokens: 348,160 | Time: 73.9s\n",
            "Step 1367/8000 | Loss: 2.4362 | LR: 1.03e-04 | Tokens: 350,208 | Time: 74.4s\n",
            "Step 1375/8000 | Loss: 2.4914 | LR: 1.03e-04 | Tokens: 352,256 | Time: 74.8s\n",
            "Step 1383/8000 | Loss: 2.4380 | LR: 1.04e-04 | Tokens: 354,304 | Time: 75.2s\n",
            "Step 1391/8000 | Loss: 2.5089 | LR: 1.04e-04 | Tokens: 356,352 | Time: 75.7s\n",
            "Step 1399/8000 | Loss: 2.4571 | LR: 1.05e-04 | Tokens: 358,400 | Time: 76.1s\n",
            "Step 1407/8000 | Loss: 2.5347 | LR: 1.06e-04 | Tokens: 360,448 | Time: 76.5s\n",
            "Step 1415/8000 | Loss: 2.4212 | LR: 1.06e-04 | Tokens: 362,496 | Time: 76.9s\n",
            "Step 1423/8000 | Loss: 2.4929 | LR: 1.07e-04 | Tokens: 364,544 | Time: 77.4s\n",
            "Step 1431/8000 | Loss: 2.3967 | LR: 1.07e-04 | Tokens: 366,592 | Time: 77.8s\n",
            "Step 1439/8000 | Loss: 2.4132 | LR: 1.08e-04 | Tokens: 368,640 | Time: 78.2s\n",
            "Step 1447/8000 | Loss: 2.4182 | LR: 1.09e-04 | Tokens: 370,688 | Time: 78.6s\n",
            "Step 1455/8000 | Loss: 2.4140 | LR: 1.09e-04 | Tokens: 372,736 | Time: 79.0s\n",
            "Step 1463/8000 | Loss: 2.3708 | LR: 1.10e-04 | Tokens: 374,784 | Time: 79.4s\n",
            "Step 1471/8000 | Loss: 2.3715 | LR: 1.10e-04 | Tokens: 376,832 | Time: 79.8s\n",
            "Step 1479/8000 | Loss: 2.4113 | LR: 1.11e-04 | Tokens: 378,880 | Time: 80.3s\n",
            "Step 1487/8000 | Loss: 2.3551 | LR: 1.12e-04 | Tokens: 380,928 | Time: 80.7s\n",
            "Step 1495/8000 | Loss: 2.3381 | LR: 1.12e-04 | Tokens: 382,976 | Time: 81.2s\n",
            "Step 1503/8000 | Loss: 2.4373 | LR: 1.13e-04 | Tokens: 385,024 | Time: 81.6s\n",
            "Step 1511/8000 | Loss: 2.4298 | LR: 1.13e-04 | Tokens: 387,072 | Time: 82.0s\n",
            "Step 1519/8000 | Loss: 2.3863 | LR: 1.14e-04 | Tokens: 389,120 | Time: 82.5s\n",
            "Step 1527/8000 | Loss: 2.4155 | LR: 1.15e-04 | Tokens: 391,168 | Time: 82.9s\n",
            "Step 1535/8000 | Loss: 2.4004 | LR: 1.15e-04 | Tokens: 393,216 | Time: 83.3s\n",
            "Step 1543/8000 | Loss: 2.3156 | LR: 1.16e-04 | Tokens: 395,264 | Time: 83.8s\n",
            "Step 1551/8000 | Loss: 2.3963 | LR: 1.16e-04 | Tokens: 397,312 | Time: 84.3s\n",
            "Step 1559/8000 | Loss: 2.3761 | LR: 1.17e-04 | Tokens: 399,360 | Time: 84.7s\n",
            "Step 1567/8000 | Loss: 2.3352 | LR: 1.18e-04 | Tokens: 401,408 | Time: 85.1s\n",
            "Step 1575/8000 | Loss: 2.3967 | LR: 1.18e-04 | Tokens: 403,456 | Time: 85.5s\n",
            "Step 1583/8000 | Loss: 2.4336 | LR: 1.19e-04 | Tokens: 405,504 | Time: 86.0s\n",
            "Step 1591/8000 | Loss: 2.4503 | LR: 1.19e-04 | Tokens: 407,552 | Time: 86.4s\n",
            "Step 1599/8000 | Loss: 2.3487 | LR: 1.20e-04 | Tokens: 409,600 | Time: 86.8s\n",
            "Step 1607/8000 | Loss: 2.2770 | LR: 1.21e-04 | Tokens: 411,648 | Time: 87.2s\n",
            "Step 1615/8000 | Loss: 2.3114 | LR: 1.21e-04 | Tokens: 413,696 | Time: 87.7s\n",
            "Step 1623/8000 | Loss: 2.3329 | LR: 1.22e-04 | Tokens: 415,744 | Time: 88.1s\n",
            "Step 1631/8000 | Loss: 2.3203 | LR: 1.22e-04 | Tokens: 417,792 | Time: 88.5s\n",
            "Step 1639/8000 | Loss: 2.3164 | LR: 1.23e-04 | Tokens: 419,840 | Time: 88.9s\n",
            "Step 1647/8000 | Loss: 2.3509 | LR: 1.24e-04 | Tokens: 421,888 | Time: 89.4s\n",
            "Step 1655/8000 | Loss: 2.3125 | LR: 1.24e-04 | Tokens: 423,936 | Time: 89.8s\n",
            "Step 1663/8000 | Loss: 2.3011 | LR: 1.25e-04 | Tokens: 425,984 | Time: 90.3s\n",
            "Step 1671/8000 | Loss: 2.2893 | LR: 1.25e-04 | Tokens: 428,032 | Time: 90.7s\n",
            "Step 1679/8000 | Loss: 2.2556 | LR: 1.26e-04 | Tokens: 430,080 | Time: 91.1s\n",
            "Step 1687/8000 | Loss: 2.2712 | LR: 1.27e-04 | Tokens: 432,128 | Time: 91.5s\n",
            "Step 1695/8000 | Loss: 2.3094 | LR: 1.27e-04 | Tokens: 434,176 | Time: 92.0s\n",
            "Step 1703/8000 | Loss: 2.2788 | LR: 1.28e-04 | Tokens: 436,224 | Time: 92.3s\n",
            "Step 1711/8000 | Loss: 2.2341 | LR: 1.28e-04 | Tokens: 438,272 | Time: 92.8s\n",
            "Step 1719/8000 | Loss: 2.3085 | LR: 1.29e-04 | Tokens: 440,320 | Time: 93.2s\n",
            "Step 1727/8000 | Loss: 2.2712 | LR: 1.30e-04 | Tokens: 442,368 | Time: 93.6s\n",
            "Step 1735/8000 | Loss: 2.3131 | LR: 1.30e-04 | Tokens: 444,416 | Time: 94.1s\n",
            "Step 1743/8000 | Loss: 2.3103 | LR: 1.31e-04 | Tokens: 446,464 | Time: 94.5s\n",
            "Step 1751/8000 | Loss: 2.2682 | LR: 1.31e-04 | Tokens: 448,512 | Time: 95.0s\n",
            "Step 1759/8000 | Loss: 2.2706 | LR: 1.32e-04 | Tokens: 450,560 | Time: 95.5s\n",
            "Step 1767/8000 | Loss: 2.2389 | LR: 1.33e-04 | Tokens: 452,608 | Time: 95.9s\n",
            "Step 1775/8000 | Loss: 2.2500 | LR: 1.33e-04 | Tokens: 454,656 | Time: 96.3s\n",
            "Step 1783/8000 | Loss: 2.2818 | LR: 1.34e-04 | Tokens: 456,704 | Time: 96.8s\n",
            "Step 1791/8000 | Loss: 2.2246 | LR: 1.34e-04 | Tokens: 458,752 | Time: 97.2s\n",
            "Step 1799/8000 | Loss: 2.1925 | LR: 1.35e-04 | Tokens: 460,800 | Time: 97.6s\n",
            "Step 1807/8000 | Loss: 2.2376 | LR: 1.36e-04 | Tokens: 462,848 | Time: 98.0s\n",
            "Step 1815/8000 | Loss: 2.2768 | LR: 1.36e-04 | Tokens: 464,896 | Time: 98.5s\n",
            "Step 1823/8000 | Loss: 2.2137 | LR: 1.37e-04 | Tokens: 466,944 | Time: 98.9s\n",
            "Step 1831/8000 | Loss: 2.2413 | LR: 1.37e-04 | Tokens: 468,992 | Time: 99.3s\n",
            "Step 1839/8000 | Loss: 2.2355 | LR: 1.38e-04 | Tokens: 471,040 | Time: 99.8s\n",
            "Step 1847/8000 | Loss: 2.1930 | LR: 1.39e-04 | Tokens: 473,088 | Time: 100.2s\n",
            "Step 1855/8000 | Loss: 2.1989 | LR: 1.39e-04 | Tokens: 475,136 | Time: 100.6s\n",
            "Step 1863/8000 | Loss: 2.1714 | LR: 1.40e-04 | Tokens: 477,184 | Time: 101.0s\n",
            "Step 1871/8000 | Loss: 2.1889 | LR: 1.40e-04 | Tokens: 479,232 | Time: 101.5s\n",
            "Step 1879/8000 | Loss: 2.1760 | LR: 1.41e-04 | Tokens: 481,280 | Time: 102.0s\n",
            "Step 1887/8000 | Loss: 2.2030 | LR: 1.42e-04 | Tokens: 483,328 | Time: 102.4s\n",
            "Step 1895/8000 | Loss: 2.1591 | LR: 1.42e-04 | Tokens: 485,376 | Time: 102.8s\n",
            "Step 1903/8000 | Loss: 2.2686 | LR: 1.43e-04 | Tokens: 487,424 | Time: 103.3s\n",
            "Step 1911/8000 | Loss: 2.1514 | LR: 1.43e-04 | Tokens: 489,472 | Time: 103.7s\n",
            "Step 1919/8000 | Loss: 2.1038 | LR: 1.44e-04 | Tokens: 491,520 | Time: 104.2s\n",
            "Step 1927/8000 | Loss: 2.1151 | LR: 1.45e-04 | Tokens: 493,568 | Time: 104.6s\n",
            "Step 1935/8000 | Loss: 2.1270 | LR: 1.45e-04 | Tokens: 495,616 | Time: 105.1s\n",
            "Step 1943/8000 | Loss: 2.2209 | LR: 1.46e-04 | Tokens: 497,664 | Time: 105.5s\n",
            "Step 1951/8000 | Loss: 2.1128 | LR: 1.46e-04 | Tokens: 499,712 | Time: 105.9s\n",
            "Step 1959/8000 | Loss: 2.1538 | LR: 1.47e-04 | Tokens: 501,760 | Time: 106.3s\n",
            "Step 1967/8000 | Loss: 2.1438 | LR: 1.48e-04 | Tokens: 503,808 | Time: 106.8s\n",
            "Step 1975/8000 | Loss: 2.0919 | LR: 1.48e-04 | Tokens: 505,856 | Time: 107.2s\n",
            "Step 1983/8000 | Loss: 2.1714 | LR: 1.49e-04 | Tokens: 507,904 | Time: 107.6s\n",
            "Step 1991/8000 | Loss: 2.1277 | LR: 1.49e-04 | Tokens: 509,952 | Time: 108.0s\n",
            "Step 1999/8000 | Loss: 2.1203 | LR: 1.50e-04 | Tokens: 512,000 | Time: 108.4s\n",
            "Step 2007/8000 | Loss: 2.1614 | LR: 1.51e-04 | Tokens: 514,048 | Time: 108.8s\n",
            "Step 2015/8000 | Loss: 2.1555 | LR: 1.51e-04 | Tokens: 516,096 | Time: 109.2s\n",
            "Step 2023/8000 | Loss: 2.1168 | LR: 1.52e-04 | Tokens: 518,144 | Time: 109.7s\n",
            "Step 2031/8000 | Loss: 2.0906 | LR: 1.52e-04 | Tokens: 520,192 | Time: 110.1s\n",
            "Step 2039/8000 | Loss: 2.1105 | LR: 1.53e-04 | Tokens: 522,240 | Time: 110.5s\n",
            "Step 2047/8000 | Loss: 2.1285 | LR: 1.54e-04 | Tokens: 524,288 | Time: 110.9s\n",
            "Step 2055/8000 | Loss: 2.0452 | LR: 1.54e-04 | Tokens: 526,336 | Time: 111.4s\n",
            "Step 2063/8000 | Loss: 2.2404 | LR: 1.55e-04 | Tokens: 528,384 | Time: 111.8s\n",
            "Step 2071/8000 | Loss: 2.0239 | LR: 1.55e-04 | Tokens: 530,432 | Time: 112.3s\n",
            "Step 2079/8000 | Loss: 2.1148 | LR: 1.56e-04 | Tokens: 532,480 | Time: 112.7s\n",
            "Step 2087/8000 | Loss: 2.1105 | LR: 1.57e-04 | Tokens: 534,528 | Time: 113.1s\n",
            "Step 2095/8000 | Loss: 2.1340 | LR: 1.57e-04 | Tokens: 536,576 | Time: 113.5s\n",
            "Step 2103/8000 | Loss: 2.1096 | LR: 1.58e-04 | Tokens: 538,624 | Time: 114.0s\n",
            "Step 2111/8000 | Loss: 2.0653 | LR: 1.58e-04 | Tokens: 540,672 | Time: 114.4s\n",
            "Step 2119/8000 | Loss: 2.1861 | LR: 1.59e-04 | Tokens: 542,720 | Time: 114.9s\n",
            "Step 2127/8000 | Loss: 2.2088 | LR: 1.60e-04 | Tokens: 544,768 | Time: 115.3s\n",
            "Step 2135/8000 | Loss: 2.1183 | LR: 1.60e-04 | Tokens: 546,816 | Time: 115.8s\n",
            "Step 2143/8000 | Loss: 2.0892 | LR: 1.61e-04 | Tokens: 548,864 | Time: 116.2s\n",
            "Step 2151/8000 | Loss: 2.0867 | LR: 1.61e-04 | Tokens: 550,912 | Time: 116.6s\n",
            "Step 2159/8000 | Loss: 2.1216 | LR: 1.62e-04 | Tokens: 552,960 | Time: 117.0s\n",
            "Step 2167/8000 | Loss: 2.1146 | LR: 1.63e-04 | Tokens: 555,008 | Time: 117.5s\n",
            "Step 2175/8000 | Loss: 2.0731 | LR: 1.63e-04 | Tokens: 557,056 | Time: 117.9s\n",
            "Step 2183/8000 | Loss: 2.0916 | LR: 1.64e-04 | Tokens: 559,104 | Time: 118.3s\n",
            "Step 2191/8000 | Loss: 2.0278 | LR: 1.64e-04 | Tokens: 561,152 | Time: 118.7s\n",
            "Step 2199/8000 | Loss: 2.1176 | LR: 1.65e-04 | Tokens: 563,200 | Time: 119.2s\n",
            "Step 2207/8000 | Loss: 2.0495 | LR: 1.66e-04 | Tokens: 565,248 | Time: 119.6s\n",
            "Step 2215/8000 | Loss: 2.0937 | LR: 1.66e-04 | Tokens: 567,296 | Time: 120.0s\n",
            "Step 2223/8000 | Loss: 2.0678 | LR: 1.67e-04 | Tokens: 569,344 | Time: 120.4s\n",
            "Step 2231/8000 | Loss: 2.0215 | LR: 1.67e-04 | Tokens: 571,392 | Time: 120.9s\n",
            "Step 2239/8000 | Loss: 2.0130 | LR: 1.68e-04 | Tokens: 573,440 | Time: 121.3s\n",
            "Step 2247/8000 | Loss: 2.0671 | LR: 1.69e-04 | Tokens: 575,488 | Time: 121.7s\n",
            "Step 2255/8000 | Loss: 1.9880 | LR: 1.69e-04 | Tokens: 577,536 | Time: 122.1s\n",
            "Step 2263/8000 | Loss: 1.9828 | LR: 1.70e-04 | Tokens: 579,584 | Time: 122.5s\n",
            "Step 2271/8000 | Loss: 2.0152 | LR: 1.70e-04 | Tokens: 581,632 | Time: 123.0s\n",
            "Step 2279/8000 | Loss: 1.9708 | LR: 1.71e-04 | Tokens: 583,680 | Time: 123.4s\n",
            "Step 2287/8000 | Loss: 2.0315 | LR: 1.72e-04 | Tokens: 585,728 | Time: 123.8s\n",
            "Step 2295/8000 | Loss: 2.0098 | LR: 1.72e-04 | Tokens: 587,776 | Time: 124.2s\n",
            "Step 2303/8000 | Loss: 2.0571 | LR: 1.73e-04 | Tokens: 589,824 | Time: 124.6s\n",
            "Step 2311/8000 | Loss: 2.0973 | LR: 1.73e-04 | Tokens: 591,872 | Time: 125.0s\n",
            "Step 2319/8000 | Loss: 2.0659 | LR: 1.74e-04 | Tokens: 593,920 | Time: 125.5s\n",
            "Step 2327/8000 | Loss: 2.0262 | LR: 1.75e-04 | Tokens: 595,968 | Time: 125.9s\n",
            "Step 2335/8000 | Loss: 1.9994 | LR: 1.75e-04 | Tokens: 598,016 | Time: 126.3s\n",
            "Step 2343/8000 | Loss: 2.0203 | LR: 1.76e-04 | Tokens: 600,064 | Time: 126.8s\n",
            "Step 2351/8000 | Loss: 2.0484 | LR: 1.76e-04 | Tokens: 602,112 | Time: 127.2s\n",
            "Step 2359/8000 | Loss: 1.9325 | LR: 1.77e-04 | Tokens: 604,160 | Time: 127.6s\n",
            "Step 2367/8000 | Loss: 2.0416 | LR: 1.78e-04 | Tokens: 606,208 | Time: 128.0s\n",
            "Step 2375/8000 | Loss: 1.9644 | LR: 1.78e-04 | Tokens: 608,256 | Time: 128.5s\n",
            "Step 2383/8000 | Loss: 2.0652 | LR: 1.79e-04 | Tokens: 610,304 | Time: 128.9s\n",
            "Step 2391/8000 | Loss: 2.0086 | LR: 1.79e-04 | Tokens: 612,352 | Time: 129.3s\n",
            "Step 2399/8000 | Loss: 1.9489 | LR: 1.80e-04 | Tokens: 614,400 | Time: 129.7s\n",
            "Step 2407/8000 | Loss: 1.9579 | LR: 1.81e-04 | Tokens: 616,448 | Time: 130.1s\n",
            "Step 2415/8000 | Loss: 1.9114 | LR: 1.81e-04 | Tokens: 618,496 | Time: 130.6s\n",
            "Step 2423/8000 | Loss: 1.9881 | LR: 1.82e-04 | Tokens: 620,544 | Time: 131.0s\n",
            "Step 2431/8000 | Loss: 1.9608 | LR: 1.82e-04 | Tokens: 622,592 | Time: 131.4s\n",
            "Step 2439/8000 | Loss: 1.9149 | LR: 1.83e-04 | Tokens: 624,640 | Time: 131.9s\n",
            "Step 2447/8000 | Loss: 1.9620 | LR: 1.84e-04 | Tokens: 626,688 | Time: 132.3s\n",
            "Step 2455/8000 | Loss: 1.9281 | LR: 1.84e-04 | Tokens: 628,736 | Time: 132.7s\n",
            "Step 2463/8000 | Loss: 1.9951 | LR: 1.85e-04 | Tokens: 630,784 | Time: 133.1s\n",
            "Step 2471/8000 | Loss: 2.0780 | LR: 1.85e-04 | Tokens: 632,832 | Time: 133.6s\n",
            "Step 2479/8000 | Loss: 2.0274 | LR: 1.86e-04 | Tokens: 634,880 | Time: 134.0s\n",
            "Step 2487/8000 | Loss: 1.9420 | LR: 1.87e-04 | Tokens: 636,928 | Time: 134.4s\n",
            "Step 2495/8000 | Loss: 1.9751 | LR: 1.87e-04 | Tokens: 638,976 | Time: 134.8s\n",
            "Step 2503/8000 | Loss: 1.9381 | LR: 1.88e-04 | Tokens: 641,024 | Time: 135.2s\n",
            "Step 2511/8000 | Loss: 1.9643 | LR: 1.88e-04 | Tokens: 643,072 | Time: 135.6s\n",
            "Step 2519/8000 | Loss: 1.9810 | LR: 1.89e-04 | Tokens: 645,120 | Time: 136.1s\n",
            "Step 2527/8000 | Loss: 1.9150 | LR: 1.90e-04 | Tokens: 647,168 | Time: 136.5s\n",
            "Step 2535/8000 | Loss: 1.9083 | LR: 1.90e-04 | Tokens: 649,216 | Time: 136.9s\n",
            "Step 2543/8000 | Loss: 1.9364 | LR: 1.91e-04 | Tokens: 651,264 | Time: 137.3s\n",
            "Step 2551/8000 | Loss: 2.0200 | LR: 1.91e-04 | Tokens: 653,312 | Time: 137.7s\n",
            "Step 2559/8000 | Loss: 1.8866 | LR: 1.92e-04 | Tokens: 655,360 | Time: 138.2s\n",
            "Step 2567/8000 | Loss: 2.0089 | LR: 1.93e-04 | Tokens: 657,408 | Time: 138.6s\n",
            "Step 2575/8000 | Loss: 1.8877 | LR: 1.93e-04 | Tokens: 659,456 | Time: 139.1s\n",
            "Step 2583/8000 | Loss: 1.8916 | LR: 1.94e-04 | Tokens: 661,504 | Time: 139.5s\n",
            "Step 2591/8000 | Loss: 1.9243 | LR: 1.94e-04 | Tokens: 663,552 | Time: 139.9s\n",
            "Step 2599/8000 | Loss: 1.9734 | LR: 1.95e-04 | Tokens: 665,600 | Time: 140.4s\n",
            "Step 2607/8000 | Loss: 1.9133 | LR: 1.96e-04 | Tokens: 667,648 | Time: 140.8s\n",
            "Step 2615/8000 | Loss: 1.8339 | LR: 1.96e-04 | Tokens: 669,696 | Time: 141.2s\n",
            "Step 2623/8000 | Loss: 1.8854 | LR: 1.97e-04 | Tokens: 671,744 | Time: 141.6s\n",
            "Step 2631/8000 | Loss: 1.9671 | LR: 1.97e-04 | Tokens: 673,792 | Time: 142.0s\n",
            "Step 2639/8000 | Loss: 1.9533 | LR: 1.98e-04 | Tokens: 675,840 | Time: 142.5s\n",
            "Step 2647/8000 | Loss: 1.9216 | LR: 1.99e-04 | Tokens: 677,888 | Time: 142.9s\n",
            "Step 2655/8000 | Loss: 1.9034 | LR: 1.99e-04 | Tokens: 679,936 | Time: 143.3s\n",
            "Step 2663/8000 | Loss: 1.9933 | LR: 2.00e-04 | Tokens: 681,984 | Time: 143.8s\n",
            "Step 2671/8000 | Loss: 1.8545 | LR: 2.00e-04 | Tokens: 684,032 | Time: 144.2s\n",
            "Step 2679/8000 | Loss: 1.9123 | LR: 2.01e-04 | Tokens: 686,080 | Time: 144.7s\n",
            "Step 2687/8000 | Loss: 1.8396 | LR: 2.02e-04 | Tokens: 688,128 | Time: 145.2s\n",
            "Step 2695/8000 | Loss: 1.8418 | LR: 2.02e-04 | Tokens: 690,176 | Time: 145.6s\n",
            "Step 2703/8000 | Loss: 1.8647 | LR: 2.03e-04 | Tokens: 692,224 | Time: 146.1s\n",
            "Step 2711/8000 | Loss: 1.8906 | LR: 2.03e-04 | Tokens: 694,272 | Time: 146.5s\n",
            "Step 2719/8000 | Loss: 1.8959 | LR: 2.04e-04 | Tokens: 696,320 | Time: 146.9s\n",
            "Step 2727/8000 | Loss: 1.8698 | LR: 2.05e-04 | Tokens: 698,368 | Time: 147.4s\n",
            "Step 2735/8000 | Loss: 1.8943 | LR: 2.05e-04 | Tokens: 700,416 | Time: 147.8s\n",
            "Step 2743/8000 | Loss: 1.8309 | LR: 2.06e-04 | Tokens: 702,464 | Time: 148.2s\n",
            "Step 2751/8000 | Loss: 1.8717 | LR: 2.06e-04 | Tokens: 704,512 | Time: 148.6s\n",
            "Step 2759/8000 | Loss: 1.8729 | LR: 2.07e-04 | Tokens: 706,560 | Time: 149.0s\n",
            "Step 2767/8000 | Loss: 1.8418 | LR: 2.08e-04 | Tokens: 708,608 | Time: 149.5s\n",
            "Step 2775/8000 | Loss: 1.8577 | LR: 2.08e-04 | Tokens: 710,656 | Time: 149.9s\n",
            "Step 2783/8000 | Loss: 1.9057 | LR: 2.09e-04 | Tokens: 712,704 | Time: 150.3s\n",
            "Step 2791/8000 | Loss: 1.8181 | LR: 2.09e-04 | Tokens: 714,752 | Time: 150.7s\n",
            "Step 2799/8000 | Loss: 1.8655 | LR: 2.10e-04 | Tokens: 716,800 | Time: 151.2s\n",
            "Step 2807/8000 | Loss: 1.9606 | LR: 2.11e-04 | Tokens: 718,848 | Time: 151.6s\n",
            "Step 2815/8000 | Loss: 1.8689 | LR: 2.11e-04 | Tokens: 720,896 | Time: 152.1s\n",
            "Step 2823/8000 | Loss: 1.8320 | LR: 2.12e-04 | Tokens: 722,944 | Time: 152.5s\n",
            "Step 2831/8000 | Loss: 1.9527 | LR: 2.12e-04 | Tokens: 724,992 | Time: 152.9s\n",
            "Step 2839/8000 | Loss: 1.8589 | LR: 2.13e-04 | Tokens: 727,040 | Time: 153.4s\n",
            "Step 2847/8000 | Loss: 1.8436 | LR: 2.14e-04 | Tokens: 729,088 | Time: 153.8s\n",
            "Step 2855/8000 | Loss: 1.7998 | LR: 2.14e-04 | Tokens: 731,136 | Time: 154.2s\n",
            "Step 2863/8000 | Loss: 1.9660 | LR: 2.15e-04 | Tokens: 733,184 | Time: 154.6s\n",
            "Step 2871/8000 | Loss: 1.8291 | LR: 2.15e-04 | Tokens: 735,232 | Time: 155.0s\n",
            "Step 2879/8000 | Loss: 1.8563 | LR: 2.16e-04 | Tokens: 737,280 | Time: 155.4s\n",
            "Step 2887/8000 | Loss: 1.8234 | LR: 2.17e-04 | Tokens: 739,328 | Time: 155.9s\n",
            "Step 2895/8000 | Loss: 1.8945 | LR: 2.17e-04 | Tokens: 741,376 | Time: 156.3s\n",
            "Step 2903/8000 | Loss: 1.9180 | LR: 2.18e-04 | Tokens: 743,424 | Time: 156.7s\n",
            "Step 2911/8000 | Loss: 1.8586 | LR: 2.18e-04 | Tokens: 745,472 | Time: 157.1s\n",
            "Step 2919/8000 | Loss: 1.9334 | LR: 2.19e-04 | Tokens: 747,520 | Time: 157.5s\n",
            "Step 2927/8000 | Loss: 1.8998 | LR: 2.20e-04 | Tokens: 749,568 | Time: 158.1s\n",
            "Step 2935/8000 | Loss: 1.7841 | LR: 2.20e-04 | Tokens: 751,616 | Time: 158.5s\n",
            "Step 2943/8000 | Loss: 1.8515 | LR: 2.21e-04 | Tokens: 753,664 | Time: 158.9s\n",
            "Step 2951/8000 | Loss: 1.8712 | LR: 2.21e-04 | Tokens: 755,712 | Time: 159.4s\n",
            "Step 2959/8000 | Loss: 1.7884 | LR: 2.22e-04 | Tokens: 757,760 | Time: 159.8s\n",
            "Step 2967/8000 | Loss: 1.8293 | LR: 2.23e-04 | Tokens: 759,808 | Time: 160.2s\n",
            "Step 2975/8000 | Loss: 1.9077 | LR: 2.23e-04 | Tokens: 761,856 | Time: 160.7s\n",
            "Step 2983/8000 | Loss: 1.8731 | LR: 2.24e-04 | Tokens: 763,904 | Time: 161.2s\n",
            "Step 2991/8000 | Loss: 1.8446 | LR: 2.24e-04 | Tokens: 765,952 | Time: 161.6s\n",
            "Step 2999/8000 | Loss: 1.9059 | LR: 2.25e-04 | Tokens: 768,000 | Time: 162.0s\n",
            "Step 3007/8000 | Loss: 1.8353 | LR: 2.26e-04 | Tokens: 770,048 | Time: 162.5s\n",
            "Step 3015/8000 | Loss: 1.8785 | LR: 2.26e-04 | Tokens: 772,096 | Time: 162.9s\n",
            "Step 3023/8000 | Loss: 1.8587 | LR: 2.27e-04 | Tokens: 774,144 | Time: 163.4s\n",
            "Step 3031/8000 | Loss: 1.7670 | LR: 2.27e-04 | Tokens: 776,192 | Time: 163.8s\n",
            "Step 3039/8000 | Loss: 1.8590 | LR: 2.28e-04 | Tokens: 778,240 | Time: 164.3s\n",
            "Step 3047/8000 | Loss: 1.8306 | LR: 2.29e-04 | Tokens: 780,288 | Time: 164.7s\n",
            "Step 3055/8000 | Loss: 1.7813 | LR: 2.29e-04 | Tokens: 782,336 | Time: 165.1s\n",
            "Step 3063/8000 | Loss: 1.8041 | LR: 2.30e-04 | Tokens: 784,384 | Time: 165.5s\n",
            "Step 3071/8000 | Loss: 1.7840 | LR: 2.30e-04 | Tokens: 786,432 | Time: 166.0s\n",
            "Step 3079/8000 | Loss: 1.8916 | LR: 2.31e-04 | Tokens: 788,480 | Time: 166.4s\n",
            "Step 3087/8000 | Loss: 1.8787 | LR: 2.32e-04 | Tokens: 790,528 | Time: 166.8s\n",
            "Step 3095/8000 | Loss: 1.7761 | LR: 2.32e-04 | Tokens: 792,576 | Time: 167.2s\n",
            "Step 3103/8000 | Loss: 1.7493 | LR: 2.33e-04 | Tokens: 794,624 | Time: 167.7s\n",
            "Step 3111/8000 | Loss: 1.7681 | LR: 2.33e-04 | Tokens: 796,672 | Time: 168.1s\n",
            "Step 3119/8000 | Loss: 1.7622 | LR: 2.34e-04 | Tokens: 798,720 | Time: 168.5s\n",
            "Step 3127/8000 | Loss: 1.8199 | LR: 2.35e-04 | Tokens: 800,768 | Time: 168.9s\n",
            "Step 3135/8000 | Loss: 1.8330 | LR: 2.35e-04 | Tokens: 802,816 | Time: 169.4s\n",
            "Step 3143/8000 | Loss: 1.8295 | LR: 2.36e-04 | Tokens: 804,864 | Time: 169.8s\n",
            "Step 3151/8000 | Loss: 1.7551 | LR: 2.36e-04 | Tokens: 806,912 | Time: 170.2s\n",
            "Step 3159/8000 | Loss: 1.8752 | LR: 2.37e-04 | Tokens: 808,960 | Time: 170.6s\n",
            "Step 3167/8000 | Loss: 1.7034 | LR: 2.38e-04 | Tokens: 811,008 | Time: 171.0s\n",
            "Step 3175/8000 | Loss: 1.7909 | LR: 2.38e-04 | Tokens: 813,056 | Time: 171.4s\n",
            "Step 3183/8000 | Loss: 1.8826 | LR: 2.39e-04 | Tokens: 815,104 | Time: 171.9s\n",
            "Step 3191/8000 | Loss: 1.7669 | LR: 2.39e-04 | Tokens: 817,152 | Time: 172.3s\n",
            "Step 3199/8000 | Loss: 1.7583 | LR: 2.40e-04 | Tokens: 819,200 | Time: 172.8s\n",
            "Step 3207/8000 | Loss: 1.8430 | LR: 2.41e-04 | Tokens: 821,248 | Time: 173.2s\n",
            "Step 3215/8000 | Loss: 1.8036 | LR: 2.41e-04 | Tokens: 823,296 | Time: 173.6s\n",
            "Step 3223/8000 | Loss: 1.7278 | LR: 2.42e-04 | Tokens: 825,344 | Time: 174.0s\n",
            "Step 3231/8000 | Loss: 1.7883 | LR: 2.42e-04 | Tokens: 827,392 | Time: 174.4s\n",
            "Step 3239/8000 | Loss: 1.7655 | LR: 2.43e-04 | Tokens: 829,440 | Time: 174.9s\n",
            "Step 3247/8000 | Loss: 1.7506 | LR: 2.44e-04 | Tokens: 831,488 | Time: 175.3s\n",
            "Step 3255/8000 | Loss: 1.8041 | LR: 2.44e-04 | Tokens: 833,536 | Time: 175.7s\n",
            "Step 3263/8000 | Loss: 1.7611 | LR: 2.45e-04 | Tokens: 835,584 | Time: 176.1s\n",
            "Step 3271/8000 | Loss: 1.7958 | LR: 2.45e-04 | Tokens: 837,632 | Time: 176.6s\n",
            "Step 3279/8000 | Loss: 1.8396 | LR: 2.46e-04 | Tokens: 839,680 | Time: 177.0s\n",
            "Step 3287/8000 | Loss: 1.7679 | LR: 2.47e-04 | Tokens: 841,728 | Time: 177.4s\n",
            "Step 3295/8000 | Loss: 1.8155 | LR: 2.47e-04 | Tokens: 843,776 | Time: 177.8s\n",
            "Step 3303/8000 | Loss: 1.7848 | LR: 2.48e-04 | Tokens: 845,824 | Time: 178.3s\n",
            "Step 3311/8000 | Loss: 1.7673 | LR: 2.48e-04 | Tokens: 847,872 | Time: 178.7s\n",
            "Step 3319/8000 | Loss: 1.7504 | LR: 2.49e-04 | Tokens: 849,920 | Time: 179.1s\n",
            "Step 3327/8000 | Loss: 1.7696 | LR: 2.50e-04 | Tokens: 851,968 | Time: 179.5s\n",
            "Step 3335/8000 | Loss: 1.7156 | LR: 2.50e-04 | Tokens: 854,016 | Time: 180.0s\n",
            "Step 3343/8000 | Loss: 1.7809 | LR: 2.51e-04 | Tokens: 856,064 | Time: 180.4s\n",
            "Step 3351/8000 | Loss: 1.7898 | LR: 2.51e-04 | Tokens: 858,112 | Time: 180.9s\n",
            "Step 3359/8000 | Loss: 1.7480 | LR: 2.52e-04 | Tokens: 860,160 | Time: 181.3s\n",
            "Step 3367/8000 | Loss: 1.7687 | LR: 2.53e-04 | Tokens: 862,208 | Time: 181.7s\n",
            "Step 3375/8000 | Loss: 1.7694 | LR: 2.53e-04 | Tokens: 864,256 | Time: 182.2s\n",
            "Step 3383/8000 | Loss: 1.7550 | LR: 2.54e-04 | Tokens: 866,304 | Time: 182.6s\n",
            "Step 3391/8000 | Loss: 1.7998 | LR: 2.54e-04 | Tokens: 868,352 | Time: 183.1s\n",
            "Step 3399/8000 | Loss: 1.7133 | LR: 2.55e-04 | Tokens: 870,400 | Time: 183.5s\n",
            "Step 3407/8000 | Loss: 1.8248 | LR: 2.56e-04 | Tokens: 872,448 | Time: 183.9s\n",
            "Step 3415/8000 | Loss: 1.7414 | LR: 2.56e-04 | Tokens: 874,496 | Time: 184.3s\n",
            "Step 3423/8000 | Loss: 1.7006 | LR: 2.57e-04 | Tokens: 876,544 | Time: 184.7s\n",
            "Step 3431/8000 | Loss: 1.7986 | LR: 2.57e-04 | Tokens: 878,592 | Time: 185.1s\n",
            "Step 3439/8000 | Loss: 1.7475 | LR: 2.58e-04 | Tokens: 880,640 | Time: 185.5s\n",
            "Step 3447/8000 | Loss: 1.7140 | LR: 2.59e-04 | Tokens: 882,688 | Time: 186.0s\n",
            "Step 3455/8000 | Loss: 1.7784 | LR: 2.59e-04 | Tokens: 884,736 | Time: 186.4s\n",
            "Step 3463/8000 | Loss: 1.7284 | LR: 2.60e-04 | Tokens: 886,784 | Time: 186.8s\n",
            "Step 3471/8000 | Loss: 1.7189 | LR: 2.60e-04 | Tokens: 888,832 | Time: 187.3s\n",
            "Step 3479/8000 | Loss: 1.7472 | LR: 2.61e-04 | Tokens: 890,880 | Time: 187.7s\n",
            "Step 3487/8000 | Loss: 1.7982 | LR: 2.62e-04 | Tokens: 892,928 | Time: 188.1s\n",
            "Step 3495/8000 | Loss: 1.7165 | LR: 2.62e-04 | Tokens: 894,976 | Time: 188.5s\n",
            "Step 3503/8000 | Loss: 1.7604 | LR: 2.63e-04 | Tokens: 897,024 | Time: 188.9s\n",
            "Step 3511/8000 | Loss: 1.7708 | LR: 2.63e-04 | Tokens: 899,072 | Time: 189.4s\n",
            "Step 3519/8000 | Loss: 1.6747 | LR: 2.64e-04 | Tokens: 901,120 | Time: 189.8s\n",
            "Step 3527/8000 | Loss: 1.7799 | LR: 2.65e-04 | Tokens: 903,168 | Time: 190.2s\n",
            "Step 3535/8000 | Loss: 1.7521 | LR: 2.65e-04 | Tokens: 905,216 | Time: 190.7s\n",
            "Step 3543/8000 | Loss: 1.7732 | LR: 2.66e-04 | Tokens: 907,264 | Time: 191.1s\n",
            "Step 3551/8000 | Loss: 1.8374 | LR: 2.66e-04 | Tokens: 909,312 | Time: 191.5s\n",
            "Step 3559/8000 | Loss: 1.7001 | LR: 2.67e-04 | Tokens: 911,360 | Time: 191.9s\n",
            "Step 3567/8000 | Loss: 1.7043 | LR: 2.68e-04 | Tokens: 913,408 | Time: 192.4s\n",
            "Checkpoint saved: checkpoints/pretraining_notebook/final.pt\n",
            "\n",
            "Pre-training complete! Total time: 0.05 hours\n",
            "Total tokens processed: 913,408\n",
            "\n",
            "======================================================================\n",
            "‚úÖ PRE-TRAINING COMPLETE!\n",
            "======================================================================\n"
          ]
        }
      ],
      "source": [
        "# Start training\n",
        "print(\"\\n\" + \"=\" * 70)\n",
        "print(\"STARTING BASE PRE-TRAINING\")\n",
        "print(\"=\" * 70)\n",
        "\n",
        "if not USE_GPU:\n",
        "    print(\"‚ö†Ô∏è  Running on CPU - this will be slow!\")\n",
        "    print(\"    For faster training, use Google Colab with GPU\")\n",
        "    print()\n",
        "\n",
        "trainer.train()\n",
        "\n",
        "print(\"\\n\" + \"=\" * 70)\n",
        "print(\"‚úÖ PRE-TRAINING COMPLETE!\")\n",
        "print(\"=\" * 70)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p_1HAAaiW_RH"
      },
      "source": [
        "## 11. Test the Trained Model\n",
        "\n",
        "Let's generate some text to see what the model learned!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 73,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m1R2-DYWW_RI",
        "outputId": "443721de-d88b-470d-dd03-c72833e01d35"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Testing text generation...\n",
            "======================================================================\n"
          ]
        }
      ],
      "source": [
        "# [REPLACEMENT FOR STEP 11 FUNCTION]\n",
        "@torch.no_grad()\n",
        "def generate_text(model, tokenizer, prompt, max_length=50, temperature=0.8, device=\"cuda\"):\n",
        "    \"\"\"Generate text continuation from a prompt.\"\"\"\n",
        "    model.eval()\n",
        "\n",
        "    # Encode prompt\n",
        "    encoded = tokenizer.encode(prompt)\n",
        "    input_ids = torch.tensor([encoded['input_ids']], dtype=torch.long).to(device)\n",
        "\n",
        "    # Generate\n",
        "    for _ in range(max_length):\n",
        "        # Forward pass\n",
        "        outputs = model(input_ids)\n",
        "\n",
        "        # --- FIX: Extract logits from dictionary ---\n",
        "        if isinstance(outputs, dict):\n",
        "            logits = outputs['logits']\n",
        "        else:\n",
        "            logits = outputs # Fallback if it's already a tensor\n",
        "\n",
        "        # Get next token logits\n",
        "        next_token_logits = logits[0, -1, :] / temperature\n",
        "        # -------------------------------------------\n",
        "\n",
        "        # Sample next token\n",
        "        probs = torch.softmax(next_token_logits, dim=-1)\n",
        "        next_token = torch.multinomial(probs, num_samples=1)\n",
        "\n",
        "        # Append to sequence\n",
        "        input_ids = torch.cat([input_ids, next_token.unsqueeze(0)], dim=1)\n",
        "\n",
        "        # Stop if EOS token\n",
        "        if next_token.item() == tokenizer.eos_token_id:\n",
        "            break\n",
        "\n",
        "    # Decode\n",
        "    generated_ids = input_ids[0].tolist()\n",
        "    return tokenizer.decode(generated_ids)\n",
        "\n",
        "print(\"Testing text generation...\")\n",
        "print(\"=\" * 70)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 77,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9nNexyoTW_RI",
        "outputId": "1cc864fa-f231-424e-92a2-5521047a893f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mathematical generation:\n",
            "Prompt: Let f: ‚Ñù ‚Üí ‚Ñù be a continuous function. Then\n",
            "Generated: Let f: ‚Ñù ‚Üí ‚Ñù be a continuous function. Thenrything the reach that are started with the attacc\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Test 1: Mathematical prompt\n",
        "math_prompt = \"Let f: ‚Ñù ‚Üí ‚Ñù be a continuous function. Then\"\n",
        "generated = generate_text(\n",
        "    model=trainer.raw_model,\n",
        "    tokenizer=tokenizer,\n",
        "    prompt=math_prompt,\n",
        "    max_length=50,\n",
        "    device=device\n",
        ")\n",
        "\n",
        "print(\"Mathematical generation:\")\n",
        "print(f\"Prompt: {math_prompt}\")\n",
        "print(f\"Generated: {generated}\")\n",
        "print()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 78,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3_edQuCIW_RI",
        "outputId": "4225e4cd-6d6b-4ef5-8e3c-7285492da42c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Theorem generation:\n",
            "Prompt: Theorem: For any prime number p, we have\n",
            "Generated: Theorem: For any prime number p, we have the hanted to mean the standard team of the card\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Test 2: Theorem prompt\n",
        "theorem_prompt = \"Theorem: For any prime number p, we have\"\n",
        "generated = generate_text(\n",
        "    model=trainer.raw_model,\n",
        "    tokenizer=tokenizer,\n",
        "    prompt=theorem_prompt,\n",
        "    max_length=50,\n",
        "    device=device\n",
        ")\n",
        "\n",
        "print(\"Theorem generation:\")\n",
        "print(f\"Prompt: {theorem_prompt}\")\n",
        "print(f\"Generated: {generated}\")\n",
        "print()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 79,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W1IrKgqoW_RI",
        "outputId": "96ae10f1-bcbf-4e67-9560-7f26bc286a39"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "General text generation:\n",
            "Prompt: The history of mathematics began in\n",
            "Generated: The history of mathematics began inmal started as one to use the location group, part\n"
          ]
        }
      ],
      "source": [
        "# Test 3: General text prompt\n",
        "general_prompt = \"The history of mathematics began in\"\n",
        "generated = generate_text(\n",
        "    model=trainer.raw_model,\n",
        "    tokenizer=tokenizer,\n",
        "    prompt=general_prompt,\n",
        "    max_length=50,\n",
        "    device=device\n",
        ")\n",
        "\n",
        "print(\"General text generation:\")\n",
        "print(f\"Prompt: {general_prompt}\")\n",
        "print(f\"Generated: {generated}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dt54FcogW_RI"
      },
      "source": [
        "## 12. Save and Load Checkpoints"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 80,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SJ7YKoa6W_RJ",
        "outputId": "7dde6566-d943-46c7-f65e-b7a50a490338"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Checkpoint saved: checkpoints/pretraining_notebook/final_notebook.pt\n",
            "‚úì Checkpoint saved to: checkpoints/pretraining_notebook/final_notebook.pt\n",
            "\n",
            "Checkpoint contains:\n",
            "  - Model weights\n",
            "  - Optimizer state\n",
            "  - Training step: 3574\n",
            "  - Tokens seen: 913,408\n"
          ]
        }
      ],
      "source": [
        "# Save final checkpoint\n",
        "checkpoint_path = Path(training_config.checkpoint_dir) / \"final_notebook.pt\"\n",
        "trainer.save_checkpoint(\"final_notebook.pt\")\n",
        "\n",
        "print(f\"‚úì Checkpoint saved to: {checkpoint_path}\")\n",
        "print(f\"\\nCheckpoint contains:\")\n",
        "print(f\"  - Model weights\")\n",
        "print(f\"  - Optimizer state\")\n",
        "print(f\"  - Training step: {trainer.global_step}\")\n",
        "print(f\"  - Tokens seen: {trainer.tokens_seen:,}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 81,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NCQGQhVzW_RJ",
        "outputId": "9b4923f7-a9c3-48fc-d482-d9553357fe75"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading checkpoint...\n",
            "\n",
            "‚úì Checkpoint loaded\n",
            "  Training step: 3574\n",
            "  Tokens seen: 913,408\n",
            "  Config: small\n"
          ]
        }
      ],
      "source": [
        "# Example: Load checkpoint\n",
        "if checkpoint_path.exists():\n",
        "    print(\"Loading checkpoint...\")\n",
        "    checkpoint = torch.load(checkpoint_path, map_location=device)\n",
        "\n",
        "    print(f\"\\n‚úì Checkpoint loaded\")\n",
        "    print(f\"  Training step: {checkpoint['global_step']}\")\n",
        "    print(f\"  Tokens seen: {checkpoint['tokens_seen']:,}\")\n",
        "    print(f\"  Config: {checkpoint['config']['model_config_name']}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xzAhD4-yW_RJ"
      },
      "source": [
        "## 13. Summary and Next Steps"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 82,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MtgfunbaW_RJ",
        "outputId": "c3cc2622-2993-472d-e099-95e5cacb6518"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "======================================================================\n",
            "PHASE 2.1 DEMONSTRATION COMPLETE!\n",
            "======================================================================\n",
            "\n",
            "‚úì Successfully demonstrated:\n",
            "  1. Streaming dataset for large-scale corpora\n",
            "  2. Mixed-domain data sampling (ArXiv + General)\n",
            "  3. Decoder-only transformer architecture\n",
            "  4. Pre-training with causal language modeling\n",
            "  5. Mixed precision training\n",
            "  6. Automatic checkpointing\n",
            "  7. Text generation from trained model\n",
            "\n",
            "Training Statistics:\n",
            "  Steps completed: 3574\n",
            "  Tokens processed: 913,408\n",
            "  Model parameters: 34,118,144\n",
            "\n",
            "Next steps for FULL pre-training:\n",
            "  1. Prepare large-scale datasets:\n",
            "     - ArXiv papers (LaTeX extraction): ~2M papers\n",
            "     - C4 corpus: 750GB of web text\n",
            "     - Wikipedia: ~6M articles\n",
            "     - Books corpus\n",
            "\n",
            "  2. Scale up training:\n",
            "     - Use base or large model\n",
            "     - Train for 100K-1M steps\n",
            "     - Use multiple GPUs with DDP:\n",
            "       torchrun --nproc_per_node=4 pretrain.py\n",
            "\n",
            "  3. Monitor with wandb:\n",
            "     python pretrain.py --use-wandb --wandb-project my-project\n",
            "\n",
            "  4. Proceed to Phase 2.2: Mathematical Fine-tuning\n",
            "     - Fine-tune on MATH dataset\n",
            "     - Add reinforcement learning\n",
            "     - Outcome supervision\n",
            "\n",
            "Checkpoints saved to: ./checkpoints/pretraining_notebook\n",
            "======================================================================\n"
          ]
        }
      ],
      "source": [
        "print(\"=\" * 70)\n",
        "print(\"PHASE 2.1 DEMONSTRATION COMPLETE!\")\n",
        "print(\"=\" * 70)\n",
        "print(\"\\n‚úì Successfully demonstrated:\")\n",
        "print(\"  1. Streaming dataset for large-scale corpora\")\n",
        "print(\"  2. Mixed-domain data sampling (ArXiv + General)\")\n",
        "print(\"  3. Decoder-only transformer architecture\")\n",
        "print(\"  4. Pre-training with causal language modeling\")\n",
        "print(\"  5. Mixed precision training\" if USE_GPU else \"  5. CPU training (demo mode)\")\n",
        "print(\"  6. Automatic checkpointing\")\n",
        "print(\"  7. Text generation from trained model\")\n",
        "print()\n",
        "print(\"Training Statistics:\")\n",
        "print(f\"  Steps completed: {trainer.global_step}\")\n",
        "print(f\"  Tokens processed: {trainer.tokens_seen:,}\")\n",
        "print(f\"  Model parameters: {num_params:,}\")\n",
        "print()\n",
        "print(\"Next steps for FULL pre-training:\")\n",
        "print(\"  1. Prepare large-scale datasets:\")\n",
        "print(\"     - ArXiv papers (LaTeX extraction): ~2M papers\")\n",
        "print(\"     - C4 corpus: 750GB of web text\")\n",
        "print(\"     - Wikipedia: ~6M articles\")\n",
        "print(\"     - Books corpus\")\n",
        "print()\n",
        "print(\"  2. Scale up training:\")\n",
        "print(\"     - Use base or large model\")\n",
        "print(\"     - Train for 100K-1M steps\")\n",
        "print(\"     - Use multiple GPUs with DDP:\")\n",
        "print(\"       torchrun --nproc_per_node=4 pretrain.py\")\n",
        "print()\n",
        "print(\"  3. Monitor with wandb:\")\n",
        "print(\"     python pretrain.py --use-wandb --wandb-project my-project\")\n",
        "print()\n",
        "print(\"  4. Proceed to Phase 2.2: Mathematical Fine-tuning\")\n",
        "print(\"     - Fine-tune on MATH dataset\")\n",
        "print(\"     - Add reinforcement learning\")\n",
        "print(\"     - Outcome supervision\")\n",
        "print()\n",
        "print(\"Checkpoints saved to:\", training_config.checkpoint_dir)\n",
        "print(\"=\" * 70)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8UtaOsRFW_RJ"
      },
      "source": [
        "## 14. (Optional) Download Checkpoint\n",
        "\n",
        "If running on Colab, you can download the checkpoint to your local machine."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 83,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        },
        "id": "-032W1VOW_RK",
        "outputId": "a3c7c621-9d4c-4c3f-9185-9a0490d65b1d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  adding: checkpoints/ (stored 0%)\n",
            "  adding: checkpoints/pretraining_notebook/ (stored 0%)\n",
            "  adding: checkpoints/pretraining_notebook/final.pt (deflated 9%)\n",
            "  adding: checkpoints/pretraining_notebook/final_notebook.pt (deflated 9%)\n",
            "Downloading checkpoint...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_575615f6-c235-46ca-baff-1ebf46995265\", \"checkpoints.zip\", 748608658)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úì Download started\n"
          ]
        }
      ],
      "source": [
        "if IN_COLAB:\n",
        "    from google.colab import files\n",
        "\n",
        "    # Zip checkpoints\n",
        "    !zip -r checkpoints.zip checkpoints/\n",
        "\n",
        "    print(\"Downloading checkpoint...\")\n",
        "    files.download('checkpoints.zip')\n",
        "    print(\"‚úì Download started\")\n",
        "else:\n",
        "    print(\"Checkpoints are saved locally at:\", training_config.checkpoint_dir)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PTaxbRxMW_RK"
      },
      "source": [
        "---\n",
        "\n",
        "## üìö Additional Resources\n",
        "\n",
        "**Documentation:**\n",
        "- See `PHASE_2_1_README.md` for comprehensive documentation\n",
        "- Run `python pretrain.py --help` for CLI options\n",
        "\n",
        "**Scaling Up:**\n",
        "```bash\n",
        "# Multi-GPU training (4 GPUs)\n",
        "torchrun --nproc_per_node=4 pretrain.py \\\n",
        "    --model-size base \\\n",
        "    --batch-size 4 \\\n",
        "    --gradient-accumulation-steps 8 \\\n",
        "    --max-steps 500000 \\\n",
        "    --mixed-precision bf16 \\\n",
        "    --use-wandb\n",
        "```\n",
        "\n",
        "**Key Papers:**\n",
        "- [Chinchilla: Training Compute-Optimal LLMs](https://arxiv.org/abs/2203.15556)\n",
        "- [LLaMA: Open Foundation LLMs](https://arxiv.org/abs/2302.13971)\n",
        "- [Minerva: Mathematical Reasoning](https://arxiv.org/abs/2206.14858)\n",
        "\n",
        "---\n",
        "\n",
        "**Happy Pre-Training! üöÄ**"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.0"
    },
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "L4"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "76b90960778e468dbbd80d4fd9ab81bd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_dd0dafc7d4454c8098c150ad8872c38b",
              "IPY_MODEL_8c685bddc56a4196aa7217ab30a801ca",
              "IPY_MODEL_e99459de05744c3ebdef58422447678f"
            ],
            "layout": "IPY_MODEL_1b1e5003790a4460b0f12d01c5cc16e4"
          }
        },
        "dd0dafc7d4454c8098c150ad8872c38b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fd052d145e184ced9308b603eccfd7c2",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_2771f703545f4055adcff9943f31a18e",
            "value": "README.md:‚Äá"
          }
        },
        "8c685bddc56a4196aa7217ab30a801ca": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f74c7fd7aa594c94a46383fd01eeb97a",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_97b764d25b9849b9902ea29b729485ca",
            "value": 1
          }
        },
        "e99459de05744c3ebdef58422447678f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8c7d3ae3edc34d8ca9dc0421011c11ef",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_b627ba95bc794891be44803240c5885a",
            "value": "‚Äá4.80k/?‚Äá[00:00&lt;00:00,‚Äá455kB/s]"
          }
        },
        "1b1e5003790a4460b0f12d01c5cc16e4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fd052d145e184ced9308b603eccfd7c2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2771f703545f4055adcff9943f31a18e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f74c7fd7aa594c94a46383fd01eeb97a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "97b764d25b9849b9902ea29b729485ca": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "8c7d3ae3edc34d8ca9dc0421011c11ef": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b627ba95bc794891be44803240c5885a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8ceb2e81b74949f9ad499779ae01a77e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_29caf808978f45d0a1ebae7da32601e5",
              "IPY_MODEL_1ec9ff7c63a549f1b4cc5846a73da744",
              "IPY_MODEL_9ea27b1fe08a4f7680df3f4d92c4ba7a"
            ],
            "layout": "IPY_MODEL_cd8fb765699141e3ad8559329d9c22d6"
          }
        },
        "29caf808978f45d0a1ebae7da32601e5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_92dcb45df2cc4d3aa042a667312b7645",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_a54fb5cbf2a54727b46cff028389046a",
            "value": "Resolving‚Äádata‚Äáfiles:‚Äá100%"
          }
        },
        "1ec9ff7c63a549f1b4cc5846a73da744": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_474e92dc97c34c3aa64a3152e390aa41",
            "max": 114,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_20a955dd76cb4e8d9c67c9d0bdc2a56e",
            "value": 114
          }
        },
        "9ea27b1fe08a4f7680df3f4d92c4ba7a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b6d144ff9cb048a1948a40b7eb4b6d08",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_c93debb0a27a4f46b61b5df0de4403fa",
            "value": "‚Äá114/114‚Äá[00:01&lt;00:00,‚Äá‚Äá7.23it/s]"
          }
        },
        "cd8fb765699141e3ad8559329d9c22d6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "92dcb45df2cc4d3aa042a667312b7645": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a54fb5cbf2a54727b46cff028389046a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "474e92dc97c34c3aa64a3152e390aa41": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "20a955dd76cb4e8d9c67c9d0bdc2a56e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "b6d144ff9cb048a1948a40b7eb4b6d08": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c93debb0a27a4f46b61b5df0de4403fa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "fe34392937574f64aae5724614f6850b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_10045d16e42540b4970a5a3e56e8dfe5",
              "IPY_MODEL_35e2b1dacda344aba7ec812419bfc614",
              "IPY_MODEL_c29ea4346fdd441fb59cc1e726defac8"
            ],
            "layout": "IPY_MODEL_b674e92d7bd146b4a61db42c43b37922"
          }
        },
        "10045d16e42540b4970a5a3e56e8dfe5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ee74f603c41549769d41f751dacba7a3",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_cfea7e0472d24d78b09d6f47d8a7081c",
            "value": "README.md:‚Äá"
          }
        },
        "35e2b1dacda344aba7ec812419bfc614": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_de82d0042d124e86be5665d1a54ccc4e",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_95be63a5f87344be8703b6228c01defe",
            "value": 1
          }
        },
        "c29ea4346fdd441fb59cc1e726defac8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_eaa5277d99844e698668316231c5af25",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_3087d0629b5f4db9b7ff1a699a251ca5",
            "value": "‚Äá41.1k/?‚Äá[00:00&lt;00:00,‚Äá4.23MB/s]"
          }
        },
        "b674e92d7bd146b4a61db42c43b37922": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ee74f603c41549769d41f751dacba7a3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cfea7e0472d24d78b09d6f47d8a7081c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "de82d0042d124e86be5665d1a54ccc4e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "95be63a5f87344be8703b6228c01defe": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "eaa5277d99844e698668316231c5af25": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3087d0629b5f4db9b7ff1a699a251ca5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "836c3b87f39f4f42a62267aece5cbf67": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_6435afb639d04839bce01c973994f255",
              "IPY_MODEL_9548fcef781c48e2af2a44d14946cd52",
              "IPY_MODEL_3a3fbe8ed91549b69caa0df281306176"
            ],
            "layout": "IPY_MODEL_a81e649fce4c4176b95547483109b846"
          }
        },
        "6435afb639d04839bce01c973994f255": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_feae3169f177470097f47b64a40d15f4",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_e1bbb861aea145b3ae46fcea88cfe456",
            "value": "Resolving‚Äádata‚Äáfiles:‚Äá100%"
          }
        },
        "9548fcef781c48e2af2a44d14946cd52": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_49a6d9455d6c4357a50d3a29c9f40e12",
            "max": 1024,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_ec927bf70a6e422eb7793cc6404cbfe3",
            "value": 1024
          }
        },
        "3a3fbe8ed91549b69caa0df281306176": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1726b1480fd14e35909b7ae8e07c5dd0",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_45101758dd514dab81e79084485f64ee",
            "value": "‚Äá1024/1024‚Äá[00:04&lt;00:00,‚Äá‚Äá2.27s/it]"
          }
        },
        "a81e649fce4c4176b95547483109b846": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "feae3169f177470097f47b64a40d15f4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e1bbb861aea145b3ae46fcea88cfe456": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "49a6d9455d6c4357a50d3a29c9f40e12": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ec927bf70a6e422eb7793cc6404cbfe3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "1726b1480fd14e35909b7ae8e07c5dd0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "45101758dd514dab81e79084485f64ee": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c7c273075c8142b7bbc7c5a9a9f73afc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_c0f90fae6a9e4d8fac55551c9f57db5c",
              "IPY_MODEL_2d27d8e95a8042378c6240ee29cf1d5e",
              "IPY_MODEL_950fbde82bc646239909ddfdc9936f6e"
            ],
            "layout": "IPY_MODEL_cbbe31c9b2c246b2996e56ec3dc40c72"
          }
        },
        "c0f90fae6a9e4d8fac55551c9f57db5c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e811602878ad4068b5893a0837d21126",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_c5adbb8919be45808142509f325ca924",
            "value": "Resolving‚Äádata‚Äáfiles:‚Äá100%"
          }
        },
        "2d27d8e95a8042378c6240ee29cf1d5e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_88ab0ea3a2094985b8cb286173506d2b",
            "max": 1024,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_286baba9d5914de89e2139a55d9bc047",
            "value": 1024
          }
        },
        "950fbde82bc646239909ddfdc9936f6e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ec6fd79933c34578ae9d70a62ff01764",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_8d776a0dbe6c451ea0a611a18e526715",
            "value": "‚Äá1024/1024‚Äá[00:00&lt;00:00,‚Äá24411.27it/s]"
          }
        },
        "cbbe31c9b2c246b2996e56ec3dc40c72": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e811602878ad4068b5893a0837d21126": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c5adbb8919be45808142509f325ca924": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "88ab0ea3a2094985b8cb286173506d2b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "286baba9d5914de89e2139a55d9bc047": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "ec6fd79933c34578ae9d70a62ff01764": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8d776a0dbe6c451ea0a611a18e526715": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}