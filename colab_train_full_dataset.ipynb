{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üßÆ AI Mathematical Olympiad - Full Training on Colab\n",
    "\n",
    "**Comprehensive Training Notebook for Mathematical Reasoning Model**\n",
    "\n",
    "This notebook trains a transformer model on the full MATH dataset (~7,500 problems) with:\n",
    "- ‚úÖ Properly sized model for available data\n",
    "- ‚úÖ Full dataset (not just 500 examples)\n",
    "- ‚úÖ Real-time monitoring and sample generation\n",
    "- ‚úÖ Early stopping and checkpointing\n",
    "- ‚úÖ GPU acceleration (50x faster than CPU)\n",
    "\n",
    "---\n",
    "\n",
    "## üìù Instructions\n",
    "\n",
    "1. **Runtime Setup**: Runtime ‚Üí Change runtime type ‚Üí GPU (T4)\n",
    "2. **Run All**: Runtime ‚Üí Run all\n",
    "3. **Training Time**: ~2-4 hours on free Colab T4 GPU\n",
    "4. **Checkpoints**: Saved to Google Drive (optional, see Step 1)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 0: Check GPU Availability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    gpu_name = torch.cuda.get_device_name(0)\n",
    "    print(f\"‚úÖ GPU Available: {gpu_name}\")\n",
    "    print(f\"   Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.2f} GB\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è No GPU detected! Go to Runtime ‚Üí Change runtime type ‚Üí GPU\")\n",
    "    print(\"   Training on CPU will be 50x slower.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Mount Google Drive (Optional - for saving checkpoints)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "import os\n",
    "\n",
    "# Uncomment the next line to save checkpoints to Google Drive\n",
    "# drive.mount('/content/drive')\n",
    "\n",
    "# Set checkpoint directory\n",
    "USE_GDRIVE = False  # Set to True if you mounted Drive\n",
    "if USE_GDRIVE:\n",
    "    CHECKPOINT_DIR = '/content/drive/MyDrive/math_model_checkpoints'\n",
    "else:\n",
    "    CHECKPOINT_DIR = '/content/checkpoints'\n",
    "\n",
    "os.makedirs(CHECKPOINT_DIR, exist_ok=True)\n",
    "print(f\"‚úÖ Checkpoints will be saved to: {CHECKPOINT_DIR}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Install Dependencies and Clone Repository"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install dependencies\n",
    "!pip install -q datasets transformers tokenizers tqdm matplotlib\n",
    "\n",
    "# Clone the repository\n",
    "!git clone https://github.com/Alpyaman/AI-Mathematical-Olympiad.git\n",
    "%cd AI-Mathematical-Olympiad\n",
    "\n",
    "print(\"‚úÖ Repository cloned and dependencies installed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Configuration - Optimized for Full Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================\n",
    "# TRAINING CONFIGURATION\n",
    "# ============================\n",
    "\n",
    "# Model Size (choose one):\n",
    "MODEL_SIZE = \"small\"  # Options: \"tiny\" (~20M params), \"small\" (~85M params), \"medium\" (~350M params)\n",
    "\n",
    "# Training Hyperparameters\n",
    "BATCH_SIZE = 8           # Increase if you have more GPU memory\n",
    "GRAD_ACCUM_STEPS = 4     # Effective batch size = 32\n",
    "LEARNING_RATE = 1e-4     # Lower than before for stability\n",
    "MAX_EPOCHS = 30          # More epochs with early stopping\n",
    "WARMUP_STEPS = 200       # Learning rate warmup\n",
    "MAX_LENGTH = 1024        # Longer sequences for full solutions\n",
    "\n",
    "# Early Stopping\n",
    "PATIENCE = 5             # Stop if no improvement for N epochs\n",
    "MIN_DELTA = 0.01         # Minimum improvement to count\n",
    "\n",
    "# Monitoring\n",
    "LOG_EVERY = 50           # Log metrics every N steps\n",
    "SAMPLE_EVERY = 200       # Generate samples every N steps\n",
    "SAVE_EVERY_EPOCH = 5     # Save checkpoint every N epochs\n",
    "\n",
    "# Dataset\n",
    "USE_FULL_DATASET = True  # True = ~7.5k examples, False = 500 examples\n",
    "TRAIN_SPLIT = 0.85       # 85% train, 10% val, 5% test\n",
    "VAL_SPLIT = 0.10\n",
    "TEST_SPLIT = 0.05\n",
    "\n",
    "print(f\"\"\"\\n{'='*60}\n",
    "TRAINING CONFIGURATION\n",
    "{'='*60}\n",
    "Model Size:        {MODEL_SIZE}\n",
    "Effective Batch:   {BATCH_SIZE * GRAD_ACCUM_STEPS}\n",
    "Learning Rate:     {LEARNING_RATE}\n",
    "Max Epochs:        {MAX_EPOCHS}\n",
    "Sequence Length:   {MAX_LENGTH}\n",
    "Full Dataset:      {USE_FULL_DATASET}\n",
    "{'='*60}\\n\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Load and Prepare Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "from tqdm import tqdm\n",
    "from src.data.data_schema import MathProblem, MathSolution, ReasoningStep, DifficultyLevel, ProblemType\n",
    "\n",
    "def convert_hf_to_schema(hf_dataset):\n",
    "    \"\"\"Convert HuggingFace MATH dataset to our schema\"\"\"\n",
    "    problems = []\n",
    "    print(\"üîÑ Converting dataset...\")\n",
    "    \n",
    "    for i, item in enumerate(tqdm(hf_dataset)):\n",
    "        # Map difficulty if available\n",
    "        level_map = {\n",
    "            1: DifficultyLevel.EASY,\n",
    "            2: DifficultyLevel.MEDIUM,\n",
    "            3: DifficultyLevel.MEDIUM,\n",
    "            4: DifficultyLevel.HARD,\n",
    "            5: DifficultyLevel.OLYMPIAD,\n",
    "        }\n",
    "        difficulty = level_map.get(item.get('level', 2), DifficultyLevel.MEDIUM)\n",
    "        \n",
    "        # Map problem type\n",
    "        type_map = {\n",
    "            'algebra': ProblemType.ALGEBRA,\n",
    "            'counting_and_probability': ProblemType.COMBINATORICS,\n",
    "            'geometry': ProblemType.GEOMETRY,\n",
    "            'intermediate_algebra': ProblemType.ALGEBRA,\n",
    "            'number_theory': ProblemType.NUMBER_THEORY,\n",
    "            'prealgebra': ProblemType.ALGEBRA,\n",
    "            'precalculus': ProblemType.ALGEBRA,\n",
    "        }\n",
    "        prob_type = type_map.get(item.get('type', 'algebra'), ProblemType.ALGEBRA)\n",
    "        \n",
    "        # Create solution (wrap in single step for now)\n",
    "        sol = MathSolution(\n",
    "            steps=[ReasoningStep(1, \"Solution\", item['solution'], None)],\n",
    "            final_answer=item['answer'],\n",
    "            answer_type=\"exact\",\n",
    "            verification=None\n",
    "        )\n",
    "        \n",
    "        prob = MathProblem(\n",
    "            problem_id=f\"MATH_{i}\",\n",
    "            problem_statement=item['problem'],\n",
    "            solution=sol,\n",
    "            difficulty=difficulty,\n",
    "            problem_type=prob_type,\n",
    "            topics=[item.get('type', 'math')],\n",
    "            source=\"MATH\",\n",
    "            year=2024\n",
    "        )\n",
    "        problems.append(prob)\n",
    "    \n",
    "    return problems\n",
    "\n",
    "# Load dataset\n",
    "print(f\"\\nüìö Loading {'FULL' if USE_FULL_DATASET else 'MATH-500'} dataset...\")\n",
    "\n",
    "if USE_FULL_DATASET:\n",
    "    # Load full MATH dataset (~7,500 problems)\n",
    "    try:\n",
    "        dataset_hf = load_dataset(\"lighteval/MATH\", split=\"train\")\n",
    "    except:\n",
    "        print(\"   Trying alternative dataset...\")\n",
    "        dataset_hf = load_dataset(\"hendrycks/math\", \"all\", split=\"train\")\n",
    "else:\n",
    "    # Load MATH-500 (small subset for quick testing)\n",
    "    dataset_hf = load_dataset(\"HuggingFaceH4/MATH-500\", split=\"test\")\n",
    "\n",
    "print(f\"   Loaded {len(dataset_hf)} problems\")\n",
    "\n",
    "# Convert to our schema\n",
    "problems = convert_hf_to_schema(dataset_hf)\n",
    "\n",
    "# Split dataset\n",
    "from src.data.dataset import split_dataset\n",
    "train_probs, val_probs, test_probs = split_dataset(\n",
    "    problems, \n",
    "    TRAIN_SPLIT, \n",
    "    VAL_SPLIT, \n",
    "    TEST_SPLIT\n",
    ")\n",
    "\n",
    "print(f\"\\n‚úÖ Dataset prepared:\")\n",
    "print(f\"   Train:      {len(train_probs)} problems\")\n",
    "print(f\"   Validation: {len(val_probs)} problems\")\n",
    "print(f\"   Test:       {len(test_probs)} problems\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Initialize Model and Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.config.model_config import MathTransformerConfig, get_small_config\n",
    "from src.model.decoder import MathTransformerDecoder\n",
    "from src.tokenizer.math_tokenizer import MathTokenizer\n",
    "from src.data.dataset import MathReasoningDataset, create_dataloaders\n",
    "\n",
    "# Model configuration\n",
    "def get_config(size=\"small\"):\n",
    "    \"\"\"Get model configuration based on size\"\"\"\n",
    "    if size == \"tiny\":\n",
    "        return MathTransformerConfig(\n",
    "            hidden_size=256,\n",
    "            num_hidden_layers=6,\n",
    "            num_attention_heads=8,\n",
    "            intermediate_size=1024,\n",
    "            max_position_embeddings=1024,\n",
    "            max_sequence_length=1024,\n",
    "            hidden_dropout=0.2,\n",
    "            attention_dropout=0.1,\n",
    "        )\n",
    "    elif size == \"small\":\n",
    "        return get_small_config()\n",
    "    elif size == \"medium\":\n",
    "        return MathTransformerConfig(\n",
    "            hidden_size=768,\n",
    "            num_hidden_layers=12,\n",
    "            num_attention_heads=12,\n",
    "            intermediate_size=3072,\n",
    "            max_position_embeddings=2048,\n",
    "            max_sequence_length=2048,\n",
    "        )\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown model size: {size}\")\n",
    "\n",
    "# Initialize\n",
    "print(\"\\nüîß Initializing model...\")\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "config = get_config(MODEL_SIZE)\n",
    "model = MathTransformerDecoder(config).to(device)\n",
    "\n",
    "# Count parameters\n",
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "print(f\"\\n‚úÖ Model initialized:\")\n",
    "print(f\"   Size:              {MODEL_SIZE}\")\n",
    "print(f\"   Total parameters:  {total_params:,}\")\n",
    "print(f\"   Trainable params:  {trainable_params:,}\")\n",
    "print(f\"   Device:            {device}\")\n",
    "print(f\"   Hidden size:       {config.hidden_size}\")\n",
    "print(f\"   Layers:            {config.num_hidden_layers}\")\n",
    "print(f\"   Attention heads:   {config.num_attention_heads}\")\n",
    "\n",
    "# Data-to-parameter ratio\n",
    "ratio = len(train_probs) / (total_params / 1e6)\n",
    "print(f\"\\nüìä Data-to-parameter ratio: {ratio:.1f} examples per million parameters\")\n",
    "if ratio < 10:\n",
    "    print(\"   ‚ö†Ô∏è WARNING: Low ratio. Consider using a smaller model or more data.\")\n",
    "elif ratio < 50:\n",
    "    print(\"   ‚ÑπÔ∏è Acceptable ratio, but more data would help.\")\n",
    "else:\n",
    "    print(\"   ‚úÖ Good ratio for this task!\")\n",
    "\n",
    "# Initialize tokenizer and datasets\n",
    "print(\"\\nüî§ Initializing tokenizer and datasets...\")\n",
    "tokenizer = MathTokenizer()\n",
    "\n",
    "train_ds = MathReasoningDataset(train_probs, tokenizer, max_length=MAX_LENGTH)\n",
    "val_ds = MathReasoningDataset(val_probs, tokenizer, max_length=MAX_LENGTH)\n",
    "\n",
    "train_loader, val_loader = create_dataloaders(\n",
    "    train_ds, \n",
    "    val_ds, \n",
    "    batch_size=BATCH_SIZE,\n",
    "    num_workers=2\n",
    ")\n",
    "\n",
    "print(f\"‚úÖ Dataloaders created:\")\n",
    "print(f\"   Train batches: {len(train_loader)}\")\n",
    "print(f\"   Val batches:   {len(val_loader)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6: Training Setup (Optimizer, Scheduler, Early Stopping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.optim import AdamW\n",
    "from torch.optim.lr_scheduler import OneCycleLR\n",
    "import numpy as np\n",
    "\n",
    "# Optimizer\n",
    "optimizer = AdamW(\n",
    "    model.parameters(),\n",
    "    lr=LEARNING_RATE,\n",
    "    weight_decay=0.01,\n",
    "    betas=(0.9, 0.95)\n",
    ")\n",
    "\n",
    "# Learning rate scheduler with warmup\n",
    "total_steps = len(train_loader) * MAX_EPOCHS // GRAD_ACCUM_STEPS\n",
    "scheduler = OneCycleLR(\n",
    "    optimizer,\n",
    "    max_lr=LEARNING_RATE,\n",
    "    total_steps=total_steps,\n",
    "    pct_start=0.05,  # 5% warmup\n",
    "    anneal_strategy='cos',\n",
    "    div_factor=25.0,\n",
    "    final_div_factor=1000.0\n",
    ")\n",
    "\n",
    "# Early stopping tracker\n",
    "class EarlyStopping:\n",
    "    def __init__(self, patience=5, min_delta=0.01):\n",
    "        self.patience = patience\n",
    "        self.min_delta = min_delta\n",
    "        self.counter = 0\n",
    "        self.best_loss = None\n",
    "        self.should_stop = False\n",
    "        \n",
    "    def __call__(self, val_loss):\n",
    "        if self.best_loss is None:\n",
    "            self.best_loss = val_loss\n",
    "        elif val_loss > self.best_loss - self.min_delta:\n",
    "            self.counter += 1\n",
    "            if self.counter >= self.patience:\n",
    "                self.should_stop = True\n",
    "        else:\n",
    "            self.best_loss = val_loss\n",
    "            self.counter = 0\n",
    "        return self.should_stop\n",
    "\n",
    "early_stopping = EarlyStopping(patience=PATIENCE, min_delta=MIN_DELTA)\n",
    "\n",
    "# Training metrics tracker\n",
    "history = {\n",
    "    'train_loss': [],\n",
    "    'val_loss': [],\n",
    "    'learning_rate': [],\n",
    "    'epoch': []\n",
    "}\n",
    "\n",
    "print(\"‚úÖ Training setup complete:\")\n",
    "print(f\"   Optimizer:     AdamW (lr={LEARNING_RATE})\")\n",
    "print(f\"   Scheduler:     OneCycleLR with warmup\")\n",
    "print(f\"   Total steps:   {total_steps:,}\")\n",
    "print(f\"   Early stopping patience: {PATIENCE} epochs\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 7: Sample Generation Function (Monitor Training Progress)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_sample(model, tokenizer, prompt, max_length=200):\n",
    "    \"\"\"Generate a sample response to monitor training progress\"\"\"\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        # Encode prompt\n",
    "        encoded = tokenizer.encode(prompt, add_special_tokens=False)\n",
    "        input_ids = torch.tensor([encoded['input_ids']]).to(device)\n",
    "        \n",
    "        # Generate\n",
    "        output_ids = model.generate(\n",
    "            input_ids,\n",
    "            max_new_tokens=max_length,\n",
    "            temperature=0.8,\n",
    "            top_k=50,\n",
    "            top_p=0.9,\n",
    "            eos_token_id=tokenizer.eos_token_id\n",
    "        )\n",
    "        \n",
    "        # Decode\n",
    "        output_text = tokenizer.decode(output_ids[0].cpu().tolist())\n",
    "    \n",
    "    model.train()\n",
    "    return output_text\n",
    "\n",
    "# Test problems for monitoring\n",
    "TEST_PROMPTS = [\n",
    "    \"Problem: Solve for x: 2x + 5 = 13\\n\\nSolution:\",\n",
    "    \"Problem: What is 7 √ó 8?\\n\\nSolution:\",\n",
    "    \"Problem: If f(x) = 3x - 2, what is f(4)?\\n\\nSolution:\"\n",
    "]\n",
    "\n",
    "print(\"‚úÖ Sample generation function ready\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 8: Main Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from datetime import datetime\n",
    "\n",
    "print(f\"\\n{'='*70}\")\n",
    "print(f\"üöÄ STARTING TRAINING\")\n",
    "print(f\"{'='*70}\")\n",
    "print(f\"Start time: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "print(f\"Device: {device}\")\n",
    "print(f\"{'='*70}\\n\")\n",
    "\n",
    "best_val_loss = float('inf')\n",
    "global_step = 0\n",
    "start_time = time.time()\n",
    "\n",
    "for epoch in range(MAX_EPOCHS):\n",
    "    epoch_start = time.time()\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    \n",
    "    pbar = tqdm(train_loader, desc=f\"Epoch {epoch+1}/{MAX_EPOCHS}\")\n",
    "    \n",
    "    for step, batch in enumerate(pbar):\n",
    "        # Move to device\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        labels = batch['labels'].to(device)\n",
    "        \n",
    "        # Forward pass\n",
    "        outputs = model(input_ids, attention_mask=attention_mask, labels=labels)\n",
    "        loss = outputs['loss'] / GRAD_ACCUM_STEPS\n",
    "        \n",
    "        # Backward pass\n",
    "        loss.backward()\n",
    "        total_loss += loss.item() * GRAD_ACCUM_STEPS\n",
    "        \n",
    "        # Update weights\n",
    "        if (step + 1) % GRAD_ACCUM_STEPS == 0:\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "            optimizer.step()\n",
    "            scheduler.step()\n",
    "            optimizer.zero_grad()\n",
    "            global_step += 1\n",
    "            \n",
    "            # Update progress bar\n",
    "            current_lr = scheduler.get_last_lr()[0]\n",
    "            pbar.set_postfix({\n",
    "                'loss': f\"{loss.item() * GRAD_ACCUM_STEPS:.4f}\",\n",
    "                'lr': f\"{current_lr:.2e}\"\n",
    "            })\n",
    "            \n",
    "            # Generate samples periodically\n",
    "            if global_step % SAMPLE_EVERY == 0:\n",
    "                print(f\"\\n\\n{'='*70}\")\n",
    "                print(f\"üìù SAMPLE GENERATION (Step {global_step})\")\n",
    "                print(f\"{'='*70}\")\n",
    "                for i, prompt in enumerate(TEST_PROMPTS[:2]):\n",
    "                    print(f\"\\nTest {i+1}: {prompt[:50]}...\")\n",
    "                    print(\"-\" * 70)\n",
    "                    sample = generate_sample(model, tokenizer, prompt, max_length=150)\n",
    "                    print(sample[:300])\n",
    "                    print(\"-\" * 70)\n",
    "                print()\n",
    "    \n",
    "    # Validation\n",
    "    model.eval()\n",
    "    val_loss = 0\n",
    "    val_steps = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(val_loader, desc=\"Validation\", leave=False):\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            attention_mask = batch['attention_mask'].to(device)\n",
    "            labels = batch['labels'].to(device)\n",
    "            \n",
    "            outputs = model(input_ids, attention_mask=attention_mask, labels=labels)\n",
    "            val_loss += outputs['loss'].item()\n",
    "            val_steps += 1\n",
    "    \n",
    "    # Calculate metrics\n",
    "    avg_train_loss = total_loss / len(train_loader)\n",
    "    avg_val_loss = val_loss / val_steps\n",
    "    epoch_time = time.time() - epoch_start\n",
    "    \n",
    "    # Update history\n",
    "    history['train_loss'].append(avg_train_loss)\n",
    "    history['val_loss'].append(avg_val_loss)\n",
    "    history['learning_rate'].append(scheduler.get_last_lr()[0])\n",
    "    history['epoch'].append(epoch + 1)\n",
    "    \n",
    "    # Print epoch summary\n",
    "    print(f\"\\n{'='*70}\")\n",
    "    print(f\"EPOCH {epoch+1}/{MAX_EPOCHS} COMPLETE\")\n",
    "    print(f\"{'='*70}\")\n",
    "    print(f\"Train Loss:      {avg_train_loss:.4f}\")\n",
    "    print(f\"Val Loss:        {avg_val_loss:.4f}\")\n",
    "    print(f\"Learning Rate:   {scheduler.get_last_lr()[0]:.2e}\")\n",
    "    print(f\"Epoch Time:      {epoch_time/60:.2f} minutes\")\n",
    "    print(f\"Total Time:      {(time.time()-start_time)/60:.2f} minutes\")\n",
    "    \n",
    "    # Save best model\n",
    "    if avg_val_loss < best_val_loss:\n",
    "        best_val_loss = avg_val_loss\n",
    "        torch.save({\n",
    "            'epoch': epoch,\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "            'val_loss': avg_val_loss,\n",
    "            'config': config,\n",
    "        }, f\"{CHECKPOINT_DIR}/best_model.pt\")\n",
    "        print(f\"‚úÖ New best model saved! (val_loss: {avg_val_loss:.4f})\")\n",
    "    \n",
    "    # Periodic checkpoint\n",
    "    if (epoch + 1) % SAVE_EVERY_EPOCH == 0:\n",
    "        torch.save({\n",
    "            'epoch': epoch,\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "            'val_loss': avg_val_loss,\n",
    "            'config': config,\n",
    "        }, f\"{CHECKPOINT_DIR}/checkpoint_epoch_{epoch+1}.pt\")\n",
    "        print(f\"üíæ Checkpoint saved (epoch {epoch+1})\")\n",
    "    \n",
    "    print(f\"{'='*70}\\n\")\n",
    "    \n",
    "    # Early stopping check\n",
    "    if early_stopping(avg_val_loss):\n",
    "        print(f\"\\n‚ö†Ô∏è Early stopping triggered after {epoch+1} epochs\")\n",
    "        print(f\"   No improvement for {PATIENCE} epochs\")\n",
    "        print(f\"   Best val loss: {best_val_loss:.4f}\")\n",
    "        break\n",
    "\n",
    "# Training complete\n",
    "total_time = time.time() - start_time\n",
    "print(f\"\\n{'='*70}\")\n",
    "print(f\"üèÅ TRAINING COMPLETE!\")\n",
    "print(f\"{'='*70}\")\n",
    "print(f\"Total epochs:     {epoch+1}\")\n",
    "print(f\"Total time:       {total_time/3600:.2f} hours\")\n",
    "print(f\"Best val loss:    {best_val_loss:.4f}\")\n",
    "print(f\"Final train loss: {avg_train_loss:.4f}\")\n",
    "print(f\"{'='*70}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 9: Visualize Training Progress"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(15, 5))\n",
    "\n",
    "# Loss curves\n",
    "axes[0].plot(history['epoch'], history['train_loss'], label='Train Loss', marker='o')\n",
    "axes[0].plot(history['epoch'], history['val_loss'], label='Val Loss', marker='s')\n",
    "axes[0].set_xlabel('Epoch')\n",
    "axes[0].set_ylabel('Loss')\n",
    "axes[0].set_title('Training and Validation Loss')\n",
    "axes[0].legend()\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# Learning rate\n",
    "axes[1].plot(history['epoch'], history['learning_rate'], marker='o', color='orange')\n",
    "axes[1].set_xlabel('Epoch')\n",
    "axes[1].set_ylabel('Learning Rate')\n",
    "axes[1].set_title('Learning Rate Schedule')\n",
    "axes[1].set_yscale('log')\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(f\"{CHECKPOINT_DIR}/training_curves.png\", dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(f\"‚úÖ Training curves saved to {CHECKPOINT_DIR}/training_curves.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 10: Load Best Model and Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load best checkpoint\n",
    "print(\"\\nüìÇ Loading best model...\")\n",
    "checkpoint = torch.load(f\"{CHECKPOINT_DIR}/best_model.pt\")\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "model.eval()\n",
    "\n",
    "print(f\"‚úÖ Best model loaded (val_loss: {checkpoint['val_loss']:.4f})\")\n",
    "print(f\"   Trained for {checkpoint['epoch']+1} epochs\")\n",
    "\n",
    "# Test on various problems\n",
    "test_problems = [\n",
    "    \"Problem: Solve for x: 3x + 7 = 22\\n\\nSolution:\",\n",
    "    \"Problem: What is the square root of 144?\\n\\nSolution:\",\n",
    "    \"Problem: If f(x) = 2x + 3, find f(5)\\n\\nSolution:\",\n",
    "    \"Problem: Calculate 15 √ó 12\\n\\nSolution:\",\n",
    "    \"Problem: Find the area of a circle with radius 5\\n\\nSolution:\"\n",
    "]\n",
    "\n",
    "print(f\"\\n{'='*70}\")\n",
    "print(\"üß™ FINAL MODEL TESTING\")\n",
    "print(f\"{'='*70}\\n\")\n",
    "\n",
    "for i, problem in enumerate(test_problems):\n",
    "    print(f\"\\n{'‚îÄ'*70}\")\n",
    "    print(f\"Test {i+1}: {problem.split('Solution:')[0].strip()}\")\n",
    "    print(f\"{'‚îÄ'*70}\")\n",
    "    \n",
    "    output = generate_sample(model, tokenizer, problem, max_length=256)\n",
    "    \n",
    "    # Extract just the solution part\n",
    "    if \"Solution:\" in output:\n",
    "        solution = output.split(\"Solution:\")[1].strip()\n",
    "        print(solution[:400])  # Print first 400 chars\n",
    "    else:\n",
    "        print(output[:400])\n",
    "    print()\n",
    "\n",
    "print(f\"{'='*70}\")\n",
    "print(\"‚úÖ Testing complete!\")\n",
    "print(f\"{'='*70}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 11: Interactive Demo - Try Your Own Problems!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def solve_math_problem(problem_text):\n",
    "    \"\"\"Solve a math problem using the trained model\"\"\"\n",
    "    prompt = f\"Problem: {problem_text}\\n\\nSolution:\"\n",
    "    output = generate_sample(model, tokenizer, prompt, max_length=400)\n",
    "    \n",
    "    # Extract solution\n",
    "    if \"Solution:\" in output:\n",
    "        solution = output.split(\"Solution:\")[1]\n",
    "        # Try to extract answer\n",
    "        if \"<answer>\" in solution and \"</answer>\" in solution:\n",
    "            answer = solution.split(\"<answer>\")[1].split(\"</answer>\")[0].strip()\n",
    "            return solution, answer\n",
    "        return solution, None\n",
    "    return output, None\n",
    "\n",
    "print(\"\\nüéØ Interactive Math Problem Solver\")\n",
    "print(\"=\"*70)\n",
    "print(\"Enter your math problem below (or press Enter to skip):\\n\")\n",
    "\n",
    "# Example usage (you can modify this)\n",
    "custom_problem = \"Find the value of x if 5x - 8 = 17\"\n",
    "\n",
    "if custom_problem:\n",
    "    print(f\"Problem: {custom_problem}\\n\")\n",
    "    solution, answer = solve_math_problem(custom_problem)\n",
    "    print(\"Solution:\")\n",
    "    print(\"-\" * 70)\n",
    "    print(solution[:500])\n",
    "    if answer:\n",
    "        print(f\"\\nFinal Answer: {answer}\")\n",
    "    print(\"-\" * 70)\n",
    "else:\n",
    "    print(\"(No custom problem provided, skipping interactive demo)\")\n",
    "\n",
    "print(\"\\n‚úÖ Demo complete! Modify the 'custom_problem' variable above to try different problems.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 12: Save Final Model Metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# Create metadata\n",
    "metadata = {\n",
    "    \"model_size\": MODEL_SIZE,\n",
    "    \"total_parameters\": total_params,\n",
    "    \"training_examples\": len(train_probs),\n",
    "    \"validation_examples\": len(val_probs),\n",
    "    \"best_val_loss\": best_val_loss,\n",
    "    \"final_epoch\": epoch + 1,\n",
    "    \"total_training_time_hours\": total_time / 3600,\n",
    "    \"hyperparameters\": {\n",
    "        \"batch_size\": BATCH_SIZE,\n",
    "        \"grad_accum_steps\": GRAD_ACCUM_STEPS,\n",
    "        \"learning_rate\": LEARNING_RATE,\n",
    "        \"max_length\": MAX_LENGTH,\n",
    "        \"warmup_steps\": WARMUP_STEPS,\n",
    "    },\n",
    "    \"model_config\": {\n",
    "        \"hidden_size\": config.hidden_size,\n",
    "        \"num_layers\": config.num_hidden_layers,\n",
    "        \"num_heads\": config.num_attention_heads,\n",
    "        \"intermediate_size\": config.intermediate_size,\n",
    "    },\n",
    "    \"dataset\": \"MATH\" if USE_FULL_DATASET else \"MATH-500\",\n",
    "    \"training_date\": datetime.now().strftime('%Y-%m-%d %H:%M:%S'),\n",
    "}\n",
    "\n",
    "# Save metadata\n",
    "with open(f\"{CHECKPOINT_DIR}/model_metadata.json\", 'w') as f:\n",
    "    json.dump(metadata, f, indent=2)\n",
    "\n",
    "print(\"\\nüìä Model Metadata:\")\n",
    "print(json.dumps(metadata, indent=2))\n",
    "print(f\"\\n‚úÖ Metadata saved to {CHECKPOINT_DIR}/model_metadata.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üéâ Training Complete!\n",
    "\n",
    "### What's Saved:\n",
    "- ‚úÖ `best_model.pt` - Best performing model checkpoint\n",
    "- ‚úÖ `checkpoint_epoch_*.pt` - Periodic checkpoints\n",
    "- ‚úÖ `training_curves.png` - Loss and LR visualization\n",
    "- ‚úÖ `model_metadata.json` - Complete training information\n",
    "\n",
    "### Next Steps:\n",
    "1. **Download the model**: From the Files panel (left sidebar)\n",
    "2. **Use locally**: Load the checkpoint in your local environment\n",
    "3. **Evaluate**: Test on the MATH test set for proper evaluation\n",
    "4. **Fine-tune**: Continue training with more data or adjust hyperparameters\n",
    "\n",
    "### Expected Results:\n",
    "- With **7,500 examples**: Model should show basic mathematical reasoning\n",
    "- **Validation loss < 1.0**: Good sign of learning\n",
    "- **Coherent outputs**: Should generate valid mathematical steps\n",
    "- **Simple problems**: Should solve basic algebra correctly\n",
    "\n",
    "### If Results are Poor:\n",
    "- ‚úÖ Try training for more epochs\n",
    "- ‚úÖ Use a smaller model (\"tiny\" size)\n",
    "- ‚úÖ Lower learning rate (5e-5)\n",
    "- ‚úÖ Add more data augmentation\n",
    "\n",
    "---\n",
    "\n",
    "**Need help?** Check the repository issues or documentation!"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
